{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import twitter\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import lxml.html as html\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import tz\n",
    "import time\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TJLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = [\"https://tjournal.ru/paper/page/{}\"]\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        for news_page in self._news_pages:\n",
    "            \n",
    "            for i in range(count):\n",
    "                page = html.parse(urlopen(news_page.format(i+min_index)))\n",
    "                divs = page.getroot().find_class('b-articles__b__title')\n",
    "\n",
    "                for div in divs:\n",
    "                    links.append(div.getchildren()[1].get(\"href\"))\n",
    "                    \n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с tjournal, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__title\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"b-article__infoline__comments\")\n",
    "        comment = int(comments[0].find(\"b\").text.replace(\" \", \"\"))\n",
    "\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infoline__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "        \n",
    "        # Type\n",
    "        news_type = \"TJ_P\"\n",
    "            \n",
    "        return {\n",
    "            \"url\": link, \n",
    "            \"title\": title, \n",
    "            \"views\": view, \n",
    "            \"comments\": comment, \n",
    "            \"news_created_date\": date, \n",
    "            \"collect_date\": datetime.today().strftime(\"%Y-%m-%d %H:%M\"),\n",
    "            \"type\": news_type\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=1, first_date=\"2017-01-01\", last_date=\"2010-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :first_date: время первой новости, которую мы скачаем\n",
    "        :last_date: время последней новости, которую мы скачаем\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        is_break = False\n",
    "        for link in links:\n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"news_created_date\"] > first_date or link_info[\"news_created_date\"] < last_date:\n",
    "                continue\n",
    "    \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VCLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = \"https://api.vc.ru/1/paper\"\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        text = requests.get(self._news_pages).text\n",
    "        json_req = json.loads(text)\n",
    "    \n",
    "        for news in json_req:\n",
    "            links.append(news[\"url\"])\n",
    "\n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с vc, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__head\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"ccount\")[0].text\n",
    "        comment = int(comments.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infopanel__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "\n",
    "        return {\n",
    "                \"url\": link, \n",
    "                \"title\": title, \n",
    "                \"views\": view, \n",
    "                \"comments\": comment, \n",
    "                \"news_created_date\": date, \n",
    "                \"collect_date\": datetime.today().strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                \"type\": \"VC\"\n",
    "               }\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, first_date=\"2010-01-01\", last_date=\"2017-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :first_date: str, дата и время первой (самой новой) новости\n",
    "        :last_date: str, дата и время последней(самой старой) новости\n",
    "        \n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        \n",
    "        for link in links:\n",
    "            \n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"news_created_date\"] < first_date or link_info[\"news_created_date\"] > last_date:\n",
    "                print \"continue\"\n",
    "                continue\n",
    "            \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterLoader:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        CONSUMER_KEY = 'BOuuaMDhNhm6yx0rzqK8bMsbI'\n",
    "        CONSUMER_SECRET = '3DybJwlkXd2vU6R385yLA8yJblYJltLtwojySD9AVs04ShauZ0'\n",
    "\n",
    "        ACCESS_TOKEN_KEY = '3712177576-of3jzZ8gNmlPDfPjPyR0Ljw1Ao2IXdTqX9dZGDZ'\n",
    "        ACCESS_TOKEN_SECRET = 'Ky7iKwByHNXX3UMfuMhv6UgVx2IhjLo3KmwpsBQz35wtG'\n",
    "\n",
    "        self.api = twitter.Api(consumer_key=CONSUMER_KEY,\n",
    "                  consumer_secret=CONSUMER_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN_KEY,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "        self._month_dict = {\"Jan\":\"1\", \"Feb\":\"2\", \"Mar\":\"3\", \"Apr\":\"4\", \"May\":\"5\", \"Jun\":\"6\", \"Jul\":\"7\", \"Aug\":\"8\", \"Sep\":\"9\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "\n",
    "        self._UTC_TIME_ZONE = tz.gettz('Europe/London')\n",
    "        self._MOSCOW_TIME_ZONE = tz.gettz('Europe/Moscow')\n",
    "        self._RATE_LIMIT = \"[{u'message': u'Rate limit exceeded', u'code': 88}]\"\n",
    "\n",
    "\n",
    "\n",
    "    def _parse_date(self, date):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата в формате твиттера - \"Sat Nov 21 17:00:29 +0000 2015\"\n",
    "        :return: str, дата в человеческом, но буржуйском формате, да еще и в Московском часовом поясе\n",
    "        \"\"\"\n",
    "        date_array = date.split(' ')\n",
    "        month = self._month_dict[date_array[1]]\n",
    "        day = int(date_array[2])\n",
    "        time = date_array[3]\n",
    "        year = date_array[5]\n",
    "\n",
    "        date = str(year)+\"-\"+str(month)+\"-\"+str(day)+\" \"+time\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        utc_date = date.replace(tzinfo=self._UTC_TIME_ZONE)\n",
    "        moscow_date = utc_date.astimezone(self._MOSCOW_TIME_ZONE)\n",
    "\n",
    "        return str(moscow_date).split(\"+\")[0]\n",
    "\n",
    "\n",
    "\n",
    "    def loadTweetWithLink(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, ключевое слово для поиска, вданном случае - ссылка на письмо\n",
    "        :return: список словариков с информацией о УНИКАЛЬНЫХ твитах по запросу link\n",
    "        \"\"\"\n",
    "        set_id = set()\n",
    "        tweet_list = []\n",
    "        result = self.api.GetSearch(term=link, count=100000)\n",
    "\n",
    "        for res in result:\n",
    "\n",
    "            tw_id = res.GetId()\n",
    "            # Если мы уже обрабатывали этот твит - идем дальше\n",
    "            if tw_id in set_id:\n",
    "                continue\n",
    "\n",
    "            retweeted_status = res.GetRetweeted_status()\n",
    "            # Если это не ретвит\n",
    "            if retweeted_status is None:\n",
    "                is_retweet = 0\n",
    "                retweeted_count = res.GetRetweetCount()\n",
    "                favorite_count = res.GetFavoriteCount()\n",
    "            else:\n",
    "                is_retweet = 1\n",
    "                retweeted_count = 0\n",
    "                favorite_count = 0\n",
    "            set_id.add(tw_id)\n",
    "\n",
    "            created_at = res.GetCreatedAt()\n",
    "            created_at = self._parse_date(created_at)\n",
    "\n",
    "            # Данные о пользователе\n",
    "            user = res.GetUser()\n",
    "            followers_count = user.followers_count\n",
    "            listed_count = user.listed_count\n",
    "            friends_count = user.friends_count\n",
    "            favourites_count = user.favourites_count\n",
    "            statuses_count = user.statuses_count\n",
    "\n",
    "\n",
    "            tw_dict= {\n",
    "                    \"url\": link,\n",
    "                    \"tw_id\":tw_id,\n",
    "                    \"retweeted_count\": retweeted_count,\n",
    "                    \"favorite_count\":favorite_count,\n",
    "                    \"is_retweet\": is_retweet,\n",
    "                    \"created_at\":created_at,\n",
    "                    \"user_followers_count\":followers_count,\n",
    "                    \"user_listed_count\": listed_count,\n",
    "                    \"user_friends_count\":friends_count,\n",
    "                    \"user_favourites_count\":favourites_count,\n",
    "                    \"user_statuses_count\":statuses_count\n",
    "                    }\n",
    "\n",
    "            tweet_list.append(tw_dict)\n",
    "\n",
    "        return tweet_list\n",
    "    \n",
    "\n",
    "    def load_tweets_by_term(self, news_list, days_after_news=3):\n",
    "        \"\"\"\n",
    "\n",
    "        :param news_list: list(str), список словариков с информацией о новости\n",
    "        :param days_after_news:  int, количество дней после публикации новости, до которой искать\n",
    "        \"\"\"\n",
    "        result_list = []\n",
    "        i = 0\n",
    "        for news in news_list:\n",
    "            tweets = []\n",
    "            try:\n",
    "                #print news\n",
    "                #until_date = self._get_next_date(news[\"created_date\"], days_after_news)\n",
    "                tweets = self.loadTweetWithLink(news)\n",
    "            except twitter.error.TwitterError as ex:\n",
    "                print str(ex)\n",
    "                if str(ex) == self._RATE_LIMIT:\n",
    "                    sleep_time = self.api.GetSleepTime(\"search/tweets\") #??? Почему-то не работает\n",
    "                    print \"Спим {} сек.\".format(sleep_time)\n",
    "                    time.sleep(sleep_time+2)\n",
    "                    tweets = self.loadTweetWithLink(news[\"url\"], until_date)\n",
    "\n",
    "            result_list+= tweets\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Собрано информация о\", i, \" новостях\"\n",
    "            \n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLEEP_TIME = 15*60\n",
    "COMMENTS_COUNT_FILE = \"Comments/comments.csv\"\n",
    "COMMENTS_TWITTER_FILE = \"Comments/twitter_comments.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n",
      "Сейчас скачано 3920 записей. Номер итерации 1\n",
      "Сейчас 2015-12-09 10:50\n",
      "Ложусь спать на 900 секунд\n",
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n",
      "Сейчас скачано 4000 записей. Номер итерации 2\n",
      "Сейчас 2015-12-09 11:07\n",
      "Ложусь спать на 900 секунд\n",
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n",
      "Сейчас скачано 4080 записей. Номер итерации 3\n",
      "Сейчас 2015-12-09 11:24\n",
      "Ложусь спать на 900 секунд\n",
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n",
      "Сейчас скачано 4160 записей. Номер итерации 4\n",
      "Сейчас 2015-12-09 11:41\n",
      "Ложусь спать на 900 секунд\n"
     ]
    },
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(122 bytes read, 3030 more expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e8015cc31940>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtj_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTJLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tj_news_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mvc_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVCLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tj_news_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtj_pages\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvc_pages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6c477763e890>\u001b[0m in \u001b[0;36mget_tj_news_info\u001b[1;34m(self, min_index, count, first_date, last_date)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mis_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mlink_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_link_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;31m# Если заданное время не подходит\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlink_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"news_created_date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mfirst_date\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlink_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"news_created_date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlast_date\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6c477763e890>\u001b[0m in \u001b[0;36mget_link_info\u001b[1;34m(self, link)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mс\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mд\u001b[0m\u001b[0;31mа\u001b[0m\u001b[0;31mн\u001b[0m\u001b[0;31mн\u001b[0m\u001b[0;31mы\u001b[0m\u001b[0;31mм\u001b[0m\u001b[0;31mи\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mс\u001b[0m\u001b[0;31mо\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mс\u001b[0m\u001b[0;31mт\u001b[0m\u001b[0;31mр\u001b[0m\u001b[0;31mа\u001b[0m\u001b[0;31mн\u001b[0m\u001b[0;31mи\u001b[0m\u001b[0;31mц\u001b[0m\u001b[0;31mы\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \"\"\"\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/lxml/html/__init__.pyc\u001b[0m in \u001b[0;36mparse\u001b[1;34m(filename_or_url, parser, base_url, **kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparser\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml_parser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_contains_block_level_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mlxml.etree.pyx\u001b[0m in \u001b[0;36mlxml.etree.parse (src/lxml/lxml.etree.c:72517)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocument (src/lxml/lxml.etree.c:106204)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseFilelikeDocument (src/lxml/lxml.etree.c:106464)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocFromFilelike (src/lxml/lxml.etree.c:105354)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._BaseParser._parseDocFromFilelike (src/lxml/lxml.etree.c:100481)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:94350)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleParseResult (src/lxml/lxml.etree.c:95751)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mlxml.etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored (src/lxml/lxml.etree.c:10323)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FileReaderContext.copyToBuffer (src/lxml/lxml.etree.c:92121)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;31m# fragmentation issues on many platforms.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m                 \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m             \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[0mamt\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(122 bytes read, 3030 more expected)"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while (i<100):\n",
    "    i+=1\n",
    "    tj_pages = TJLoader().get_tj_news_info()\n",
    "    vc_pages = VCLoader().get_tj_news_info()\n",
    "    new_df = pd.DataFrame(tj_pages+vc_pages)\n",
    "    \n",
    "    prev_df = pd.read_csv(COMMENTS_COUNT_FILE, sep=\",\")\n",
    "    df = (prev_df.append(new_df)).reset_index(drop=True)\n",
    "    \n",
    "    print \"Сейчас скачано {} записей. Номер итерации {}\".format(len(df), i)\n",
    "    \n",
    "    df.to_csv(COMMENTS_COUNT_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)    \n",
    "    print \"Сейчас \" + datetime.today().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    print \"Ложусь спать на {} секунд\".format(SLEEP_TIME)\n",
    "    time.sleep(SLEEP_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собрано информация о 10  новостях\n",
      "Собрано информация о 20  новостях\n",
      "Собрано информация о 30  новостях\n",
      "Собрано информация о 40  новостях\n",
      "Собрано информация о 50  новостях\n",
      "Собрано информация о 60  новостях\n",
      "Собрано информация о 70  новостях\n",
      "Собрано информация о 80  новостях\n",
      "Собрано информация о 90  новостях\n",
      "Собрано информация о 100  новостях\n",
      "Собрано информация о 110  новостях\n",
      "Собрано информация о 120  новостях\n",
      "Собрано информация о 130  новостях\n",
      "Собрано информация о 140  новостях\n",
      "Собрано информация о 150  новостях\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(COMMENTS_COUNT_FILE, sep=\",\") # читаем\n",
    "pages = df[\"url\"].unique()\n",
    "tw = TwitterLoader()\n",
    "tw_df = tw.load_tweets_by_term(pages)\n",
    "tw_df = pd.DataFrame(tw_df)\n",
    "tw_df_prev = pd.read_csv(COMMENTS_TWITTER_FILE, sep=\",\")\n",
    "tw_df = tw_df_prev.append(tw_df)\n",
    "tw_df.to_csv(COMMENTS_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Удаляет повторяющиеся записи\n",
    "def drop_duplucates(df, field):\n",
    "    # Сначала для твиттера\n",
    "    last_size = len(df)\n",
    "    dupl = df[field].duplicated()\n",
    "    dupl = np.invert((dupl.as_matrix()))\n",
    "    df = df[dupl]\n",
    "    print \"Удалено \", last_size-len(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def diff_date_minutes(early_date, later_date, format=1):\n",
    "    early_date = datetime.strptime(early_date, '%Y-%m-%d %H:%M')\n",
    "    if format == 1:\n",
    "        later_date = datetime.strptime(later_date, '%Y-%m-%d %H:%M:%S')\n",
    "    else:\n",
    "        later_date = datetime.strptime(later_date, '%Y-%m-%d %H:%M')\n",
    "        \n",
    "    return int((later_date-early_date).total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_news_between_collect_and_create(news_df, minutes, delta):    \n",
    "    \n",
    "    news_df[\"between_collect_and_create\"] = news_df.apply(lambda s: diff_date_minutes(s[\"news_created_date\"], s[\"collect_date\"], 2), axis=1)\n",
    "    news_df = news_df[news_df[\"between_collect_and_create\"] < minutes+delta ]\n",
    "    \n",
    "    news_df[\"is_fitted\"] = news_df.groupby('url')['between_collect_and_create'].transform(max) == news_df['between_collect_and_create']\n",
    "    \n",
    "    news_df = news_df[news_df[\"is_fitted\"]==True]\n",
    "    news_df = news_df[news_df[\"between_collect_and_create\"] > minutes-delta ]\n",
    "    \n",
    "    return news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_needed_tweets(tw_df, minutes):\n",
    "    #tw_df = tw_df[tw_df[\"url\"].isin(urls)]\n",
    "    tw_df[\"between_tweet_and_create\"] = tw_df.apply(lambda s: diff_date_minutes(s[\"news_created_date\"], s[\"created_at\"]), axis=1)\n",
    "    \n",
    "    tw_df = tw_df[tw_df[\"between_tweet_and_create\"] < minutes]\n",
    "    \n",
    "    grouped = tw_df.groupby(\"url\")\n",
    "    count_of_tweets = pd.DataFrame(grouped[\"url\"].count())\n",
    "    count_of_tweets.columns = [\"tweet_count\"]\n",
    "    count_of_tweets.reset_index(inplace=True)  \n",
    "    \n",
    "    tw_df = pd.merge(count_of_tweets, tw_df, on='url', left_index=True, right_index=False, how=\"outer\")\n",
    "    tw_df = tw_df[[\"url\", \"comments\", \"tweet_count\", \"views\", \"between_collect_and_create\"]]\n",
    "    tw_df = tw_df.drop_duplicates()\n",
    "    return tw_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(minutes, delta):\n",
    "    \n",
    "    news_df = pd.read_csv(COMMENTS_COUNT_FILE, sep=\",\")\n",
    "    tw_df = pd.read_csv(COMMENTS_TWITTER_FILE, sep=\",\")\n",
    "    \n",
    "    tw_df = drop_duplucates(tw_df, \"tw_id\")\n",
    "    \n",
    "    \n",
    "    # Имеет смысл предваритально отфильтровать news по времени, которое ищем!\n",
    "    news_df = get_news_between_collect_and_create(news_df, minutes, delta)\n",
    "\n",
    "    df = news_df.merge(tw_df, on='url', left_index=True, right_index=False)\n",
    "    \n",
    "    df = get_needed_tweets(df, minutes)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено  2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/popka/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "view_tweet_df = prepare_data(240, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>comments</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>views</th>\n",
       "      <th>between_collect_and_create</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://tjournal.ru/p/rus-devices</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>3211</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>https://vc.ru/n/drop-caro-mail-drop</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>5305</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>https://vc.ru/n/match-pass</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>19045</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>https://vc.ru/n/uber-france</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>825</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>https://vc.ru/n/ya-head-support</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1042</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>https://vc.ru/p/360-brands</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1870</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>https://vc.ru/p/big-data-cases</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2498</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>https://vc.ru/p/how-to-focus</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5833</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>https://vc.ru/p/salary-sf</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>3055</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      url  comments  tweet_count  views  \\\n",
       "31      https://tjournal.ru/p/rus-devices        32            6   3211   \n",
       "1987  https://vc.ru/n/drop-caro-mail-drop        33           33   5305   \n",
       "1185           https://vc.ru/n/match-pass        23           52  19045   \n",
       "2021          https://vc.ru/n/uber-france         2            1    825   \n",
       "2025      https://vc.ru/n/ya-head-support        15            2   1042   \n",
       "1786           https://vc.ru/p/360-brands         1            4   1870   \n",
       "2022       https://vc.ru/p/big-data-cases        11            3   2498   \n",
       "1145         https://vc.ru/p/how-to-focus         7           11   5833   \n",
       "1964            https://vc.ru/p/salary-sf         9           23   3055   \n",
       "\n",
       "      between_collect_and_create  \n",
       "31                           216  \n",
       "1987                         285  \n",
       "1185                         264  \n",
       "2021                         286  \n",
       "2025                         273  \n",
       "1786                         194  \n",
       "2022                         288  \n",
       "1145                         251  \n",
       "1964                         206  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncJekAhnuklQgw12SCmS4S1KB/j/9D0rTpQws+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa36db7390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(view_tweet_df[\"comments\"], view_tweet_df[\"tweet_count\"], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.77288558],\n",
       "       [ 0.77288558,  1.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(view_tweet_df[\"views\"], view_tweet_df[\"tweet_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.23813018],\n",
       "       [ 0.23813018,  1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(view_tweet_df[\"comments\"], view_tweet_df[\"tweet_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Чистка COMMENT_FILE\n",
    "df = pd.read_csv(COMMENTS_COUNT_FILE, sep=\",\")\n",
    "df = df[df[\"url\"] == \"\"]\n",
    "df.to_csv(COMMENTS_COUNT_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
