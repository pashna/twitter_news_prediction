{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import twitter\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import lxml.html as html\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import tz\n",
    "import time\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT_NEWS_FILE = \"news.csv\"\n",
    "OUT_TWITTER_FILE = \"twitter.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TJLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = [\"https://tjournal.ru/paper/page/{}\"]#, \"https://tjournal.ru/club/news/recent/page/{}\"]\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        for news_page in self._news_pages:\n",
    "            \n",
    "            for i in range(count):\n",
    "                page = html.parse(urlopen(news_page.format(i+min_index)))\n",
    "                divs = page.getroot().find_class('b-articles__b__title')\n",
    "\n",
    "                for div in divs:\n",
    "                    links.append(div.getchildren()[1].get(\"href\"))\n",
    "                    \n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с tjournal, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__title\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"b-article__infoline__comments\")\n",
    "        comment = int(comments[0].find(\"b\").text.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-article__tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infoline__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "        # Первоисточник\n",
    "        source = root.find_class(\"b-article__link\")\n",
    "        if len(source) != 0:\n",
    "            source = source[0].getchildren()[0].getchildren()[1].getchildren()[0].text\n",
    "        else:\n",
    "            source = None\n",
    "        \n",
    "        # Type\n",
    "        if \"tjournal.ru/c/\" in link:\n",
    "            news_type = \"TJ_C\"\n",
    "        else:\n",
    "            news_type = \"TJ_P\"\n",
    "            \n",
    "        return {\n",
    "            \"url\": link, \n",
    "            \"title\": title, \n",
    "            \"views\": view, \n",
    "            \"comments\": comment, \n",
    "            \"tags\": tag_list, \n",
    "            \"date\": date, \n",
    "            \"type\": news_type, \n",
    "            \"source\": source}\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, first_date=\"2017-01-01\", last_date=\"2010-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :first_date: время первой новости, которую мы скачаем\n",
    "        :last_date: время последней новости, которую мы скачаем\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        is_break = False\n",
    "        for link in links:\n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"date\"] > first_date or link_info[\"date\"] < last_date:\n",
    "                continue\n",
    "    \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VCLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = \"https://api.vc.ru/1/paper\"\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        text = requests.get(self._news_pages).text\n",
    "        json_req = json.loads(text)\n",
    "    \n",
    "        for news in json_req:\n",
    "            links.append(news[\"url\"])\n",
    "\n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с vc, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__head\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"ccount\")[0].text\n",
    "        comment = int(comments.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infopanel__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "\n",
    "        return {\"title\": title, \"views\": view, \"comments\": comment, \"tags\": tag_list, \"date\": date, \"url\": link, \"type\": \"VC\"}\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, first_date=\"2010-01-01\", last_date=\"2017-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :first_date: str, дата и время первой (самой новой) новости\n",
    "        :last_date: str, дата и время последней(самой старой) новости\n",
    "        \n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        \n",
    "        for link in links:\n",
    "            \n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"date\"] > first_date or link_info[\"date\"] < last_date:\n",
    "                continue\n",
    "            \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RSSLoader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self._pages = [\"https://roem.ru/rss/roem-all-news.xml\", \"http://lifenews.ru/xml/feed.xml\", \"http://www.forbes.ru/newrss.xml\", \"http://rg.ru/xml/index.xml\", \"http://www.vesti.ru/vesti.rss\", \"http://lenta.ru/rss\", \"http://ria.ru/export/rss2/index.xml\"]\n",
    "        self._pages = [\"https://roem.ru/rss/roem-all-news.xml\", \"http://lifenews.ru/xml/feed.xml\", \"http://www.forbes.ru/newrss.xml\", \"http://www.vesti.ru/vesti.rss\", \"http://lenta.ru/rss\", \"http://ria.ru/export/rss2/index.xml\"]\n",
    "        self._month_dict = {\"Jan\":\"1\", \"Feb\":\"2\", \"Mar\":\"3\", \"Apr\":\"4\", \"May\":\"5\", \"Jun\":\"6\", \"Jul\":\"7\", \"Aug\":\"8\", \"Sep\":\"9\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "        \n",
    "        \n",
    "        self._UTC_TIME_ZONE = tz.gettz('Europe/London')\n",
    "        self._MOSCOW_TIME_ZONE = tz.gettz('Europe/Moscow')\n",
    "        self._RATE_LIMIT = \"[{u'message': u'Rate limit exceeded', u'code': 88}]\"\n",
    "        \n",
    "        \n",
    "    def _parse_date(self, date):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата в формате - \"Fri, 04 Dec 2015 14:45:39 +0000\"\n",
    "        :return: str, дата в человеческом, но буржуйском формате, да еще и в Московском часовом поясе\n",
    "        \"\"\"\n",
    "        timezone = date.split(\"+\")[1]\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date_array = date.split(' ')\n",
    "        \n",
    "        time = date_array[4]\n",
    "        day = int(date_array[1])\n",
    "        month = self._month_dict[date_array[2]]\n",
    "        year = date_array[3]\n",
    "\n",
    "        date = str(year)+\"-\"+str(month)+\"-\"+str(day)+\" \"+time\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        if (timezone != \"0300\"):\n",
    "            utc_date = date.replace(tzinfo=self._UTC_TIME_ZONE)\n",
    "            date = utc_date.astimezone(self._MOSCOW_TIME_ZONE)\n",
    "\n",
    "        # Обрезаем зону\n",
    "        date = str(date).split(\"+\")[0]\n",
    "        \n",
    "        # Обрезаем секунды\n",
    "        splited = date.split(\":\")\n",
    "        date = splited[0]+\":\"+splited[1]\n",
    "        return date\n",
    "    \n",
    "    \n",
    "    def _get_type(self, url):\n",
    "        url = url.replace(\"www\", \"\")\n",
    "        url = url.split(\"://\")[1]\n",
    "        url = url.split(\"/\")[0]\n",
    "        return url\n",
    "        \n",
    "    \n",
    "    def _get_hours_until_now(self, date):\n",
    "        news_date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "        now = datetime.today()\n",
    "        return float((now-news_date).total_seconds()/3600)\n",
    "        \n",
    "    def get_news_array(self, hour=8):\n",
    "        \"\"\"\n",
    "        hour: int, время последней новости\n",
    "        \"\"\"\n",
    "        news_array = []\n",
    "        for url in self._pages:\n",
    "            news_type = self._get_type(url)\n",
    "            print url\n",
    "            \n",
    "            tree = ET.ElementTree(file=urlopen(url))\n",
    "            root = tree.getroot()\n",
    "            for i in root.iter('item'):\n",
    "                link = i.find('link').text\n",
    "                title = i.find('title').text\n",
    "                date_ = i.find('pubDate').text\n",
    "                date = self._parse_date(date_)\n",
    "                \n",
    "                news_info =  {\n",
    "                    \"title\": title,\n",
    "                    \"date\": date, \n",
    "                    \"url\": link, \n",
    "                    \"type\": news_type\n",
    "                }\n",
    "                \n",
    "                if self._get_hours_until_now(date) >= hour:\n",
    "                    news_array.append(news_info)\n",
    "                \n",
    "            \n",
    "        print \"Собрано \", len(news_array), \" новостей с RSS\"\n",
    "        return news_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterLoader:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        CONSUMER_KEY = 'BOuuaMDhNhm6yx0rzqK8bMsbI'\n",
    "        CONSUMER_SECRET = '3DybJwlkXd2vU6R385yLA8yJblYJltLtwojySD9AVs04ShauZ0'\n",
    "\n",
    "        ACCESS_TOKEN_KEY = '3712177576-of3jzZ8gNmlPDfPjPyR0Ljw1Ao2IXdTqX9dZGDZ'\n",
    "        ACCESS_TOKEN_SECRET = 'Ky7iKwByHNXX3UMfuMhv6UgVx2IhjLo3KmwpsBQz35wtG'\n",
    "\n",
    "        self.api = twitter.Api(consumer_key=CONSUMER_KEY,\n",
    "                  consumer_secret=CONSUMER_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN_KEY,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "        self._month_dict = {\"Jan\":\"1\", \"Feb\":\"2\", \"Mar\":\"3\", \"Apr\":\"4\", \"May\":\"5\", \"Jun\":\"6\", \"Jul\":\"7\", \"Aug\":\"8\", \"Sep\":\"9\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "\n",
    "        self._UTC_TIME_ZONE = tz.gettz('Europe/London')\n",
    "        self._MOSCOW_TIME_ZONE = tz.gettz('Europe/Moscow')\n",
    "        self._RATE_LIMIT = \"[{u'message': u'Rate limit exceeded', u'code': 88}]\"\n",
    "\n",
    "\n",
    "\n",
    "    def _parse_date(self, date):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата в формате твиттера - \"Sat Nov 21 17:00:29 +0000 2015\"\n",
    "        :return: str, дата в человеческом, но буржуйском формате, да еще и в Московском часовом поясе\n",
    "        \"\"\"\n",
    "        date_array = date.split(' ')\n",
    "        month = self._month_dict[date_array[1]]\n",
    "        day = int(date_array[2])\n",
    "        time = date_array[3]\n",
    "        year = date_array[5]\n",
    "\n",
    "        date = str(year)+\"-\"+str(month)+\"-\"+str(day)+\" \"+time\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        utc_date = date.replace(tzinfo=self._UTC_TIME_ZONE)\n",
    "        moscow_date = utc_date.astimezone(self._MOSCOW_TIME_ZONE)\n",
    "\n",
    "        return str(moscow_date).split(\"+\")[0]\n",
    "\n",
    "\n",
    "\n",
    "    def loadTweetWithLink(self, link, date):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, ключевое слово для поиска, вданном случае - ссылка на письмо\n",
    "        :param date: str, дата, до которой искать твиты\n",
    "        :return: список словариков с информацией о УНИКАЛЬНЫХ твитах по запросу link\n",
    "        \"\"\"\n",
    "        set_id = set()\n",
    "        tweet_list = []\n",
    "        result = self.api.GetSearch(term=link, until=date, count=100000)\n",
    "\n",
    "        for res in result:\n",
    "\n",
    "            tw_id = res.GetId()\n",
    "            # Если мы уже обрабатывали этот твит - идем дальше\n",
    "            if tw_id in set_id:\n",
    "                continue\n",
    "\n",
    "            retweeted_status = res.GetRetweeted_status()\n",
    "            # Если это не ретвит\n",
    "            if retweeted_status is None:\n",
    "                is_retweet = 0\n",
    "                retweeted_count = res.GetRetweetCount()\n",
    "                favorite_count = res.GetFavoriteCount()\n",
    "            else:\n",
    "                is_retweet = 1\n",
    "                retweeted_count = 0\n",
    "                favorite_count = 0\n",
    "            set_id.add(tw_id)\n",
    "\n",
    "            created_at = res.GetCreatedAt()\n",
    "            created_at = self._parse_date(created_at)\n",
    "\n",
    "            # Данные о пользователе\n",
    "            user = res.GetUser()\n",
    "            followers_count = user.followers_count\n",
    "            listed_count = user.listed_count\n",
    "            friends_count = user.friends_count\n",
    "            favourites_count = user.favourites_count\n",
    "            statuses_count = user.statuses_count\n",
    "\n",
    "\n",
    "            tw_dict= {\n",
    "                    \"url\": link,\n",
    "                    \"tw_id\":tw_id,\n",
    "                    \"retweeted_count\": retweeted_count,\n",
    "                    \"favorite_count\":favorite_count,\n",
    "                    \"is_retweet\": is_retweet,\n",
    "                    \"created_at\":created_at,\n",
    "                    \"user_followers_count\":followers_count,\n",
    "                    \"user_listed_count\": listed_count,\n",
    "                    \"user_friends_count\":friends_count,\n",
    "                    \"user_favourites_count\":favourites_count,\n",
    "                    \"user_statuses_count\":statuses_count\n",
    "                    }\n",
    "\n",
    "            tweet_list.append(tw_dict)\n",
    "\n",
    "        return tweet_list\n",
    "\n",
    "    def _get_next_date(self, date, days):\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата\n",
    "        :param days: int, количество дней\n",
    "        :return: возвращает дату через days-дней после date\n",
    "        \"\"\"\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "        date += timedelta(days=days)\n",
    "        return str(date).split(' ')[0]\n",
    "\n",
    "\n",
    "    def load_tweets_by_term(self, news_list, days_after_news=2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param news_list: list(str), список словариков с информацией о новости\n",
    "        :param days_after_news:  int, количество дней после публикации новости, до которой искать\n",
    "        \"\"\"\n",
    "        result_list = []\n",
    "        i = 0\n",
    "        for news in news_list:\n",
    "            tweets = []\n",
    "            try:\n",
    "                until_date = self._get_next_date(news[\"date\"], days_after_news)\n",
    "                tweets = self.loadTweetWithLink(news[\"url\"], until_date)\n",
    "            except twitter.error.TwitterError as ex:\n",
    "                print str(ex)\n",
    "                if str(ex) == self._RATE_LIMIT:\n",
    "                    sleep_time = self.api.GetSleepTime(\"search/tweets\") #??? Почему-то не работает\n",
    "                    print \"Спим {} сек.\".format(sleep_time)\n",
    "                    time.sleep(sleep_time+2)\n",
    "                    tweets = self.loadTweetWithLink(news[\"url\"], until_date)\n",
    "\n",
    "            result_list+= tweets\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Собрано информация о\", i, \" новостях\"\n",
    "            \n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Подготавливаем  данные для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news_info = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "tweeter_data = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>2015-12-05 18:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[подписка, мобильные приложения, урбанизация, ...</td>\n",
       "      <td>Мнение: Приложения и интернет-сервисы убивают ...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/app-around-corner</td>\n",
       "      <td>6412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-05 16:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[bluetooth, iBeacon, bluetooth-маяки]</td>\n",
       "      <td>iBeacon-маяки для бизнеса: кейсы от EasyJet, B...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/ibeacon-marketing</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-05 14:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Россия, стартапы, китай, рейтинг, индия, мала...</td>\n",
       "      <td>Россия, Польша, Тунис и другие — топ-10 стран ...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/best-cities-for-startups</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-05 13:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Игры, книги, безбумажная библиотека, nintendo...</td>\n",
       "      <td>«Консольные войны»: Sega против Nintendo</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/sega-nintendo</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2015-12-04 21:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[uber]</td>\n",
       "      <td>Украинское министерство инфраструктуры анонсир...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/uber-ukraine</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2015-12-06 00:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Breaking Mad, депутаты, драматичные новости]</td>\n",
       "      <td>Драматичные новости недели от Breaking Mad: шт...</td>\n",
       "      <td>TJ_P</td>\n",
       "      <td>https://tjournal.ru/p/breaking-mad-cientotres</td>\n",
       "      <td>2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>2015-12-05 19:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[музыка, безопасность, Википедия, знаменитости]</td>\n",
       "      <td>Австралиец попал за кулисы к любимой группе, и...</td>\n",
       "      <td>TJ_P</td>\n",
       "      <td>https://tjournal.ru/p/peking-duk-fan</td>\n",
       "      <td>17766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>2015-12-05 14:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[фото, Instagram, Новый год, Рождество]</td>\n",
       "      <td>Праздник к нам приходит: ёлки в разных странах...</td>\n",
       "      <td>TJ_P</td>\n",
       "      <td>https://tjournal.ru/p/christmas-trees-around-t...</td>\n",
       "      <td>5326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>88</td>\n",
       "      <td>2015-12-05 12:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[СМИ, журналистика, медиа, Алексей Венедиктов,...</td>\n",
       "      <td>Леся Рябцева объявила об уходе с «Эха Москвы» ...</td>\n",
       "      <td>TJ_P</td>\n",
       "      <td>https://tjournal.ru/p/lesya-echo-off</td>\n",
       "      <td>45124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>169</td>\n",
       "      <td>2015-12-04 22:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[научные исследования, британские учёные, глуп...</td>\n",
       "      <td>Глупость любителей «глубокомысленных» цитат по...</td>\n",
       "      <td>TJ_P</td>\n",
       "      <td>https://tjournal.ru/p/stupid-quotes</td>\n",
       "      <td>27746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments              date source  \\\n",
       "0        51  2015-12-05 18:45    NaN   \n",
       "1         3  2015-12-05 16:10    NaN   \n",
       "2        26  2015-12-05 14:17    NaN   \n",
       "3         0  2015-12-05 13:07    NaN   \n",
       "4         7  2015-12-04 21:23    NaN   \n",
       "5         7  2015-12-06 00:21    NaN   \n",
       "6        21  2015-12-05 19:05    NaN   \n",
       "7        23  2015-12-05 14:01    NaN   \n",
       "8        88  2015-12-05 12:40    NaN   \n",
       "9       169  2015-12-04 22:20    NaN   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [подписка, мобильные приложения, урбанизация, ...   \n",
       "1              [bluetooth, iBeacon, bluetooth-маяки]   \n",
       "2  [Россия, стартапы, китай, рейтинг, индия, мала...   \n",
       "3  [Игры, книги, безбумажная библиотека, nintendo...   \n",
       "4                                             [uber]   \n",
       "5      [Breaking Mad, депутаты, драматичные новости]   \n",
       "6    [музыка, безопасность, Википедия, знаменитости]   \n",
       "7            [фото, Instagram, Новый год, Рождество]   \n",
       "8  [СМИ, журналистика, медиа, Алексей Венедиктов,...   \n",
       "9  [научные исследования, британские учёные, глуп...   \n",
       "\n",
       "                                               title  type  \\\n",
       "0  Мнение: Приложения и интернет-сервисы убивают ...    VC   \n",
       "1  iBeacon-маяки для бизнеса: кейсы от EasyJet, B...    VC   \n",
       "2  Россия, Польша, Тунис и другие — топ-10 стран ...    VC   \n",
       "3           «Консольные войны»: Sega против Nintendo    VC   \n",
       "4  Украинское министерство инфраструктуры анонсир...    VC   \n",
       "5  Драматичные новости недели от Breaking Mad: шт...  TJ_P   \n",
       "6  Австралиец попал за кулисы к любимой группе, и...  TJ_P   \n",
       "7  Праздник к нам приходит: ёлки в разных странах...  TJ_P   \n",
       "8  Леся Рябцева объявила об уходе с «Эха Москвы» ...  TJ_P   \n",
       "9  Глупость любителей «глубокомысленных» цитат по...  TJ_P   \n",
       "\n",
       "                                                 url  views  \n",
       "0                  https://vc.ru/p/app-around-corner   6412  \n",
       "1                  https://vc.ru/p/ibeacon-marketing   1644  \n",
       "2           https://vc.ru/p/best-cities-for-startups   3950  \n",
       "3                      https://vc.ru/p/sega-nintendo   1817  \n",
       "4                       https://vc.ru/n/uber-ukraine   3367  \n",
       "5      https://tjournal.ru/p/breaking-mad-cientotres   2233  \n",
       "6               https://tjournal.ru/p/peking-duk-fan  17766  \n",
       "7  https://tjournal.ru/p/christmas-trees-around-t...   5326  \n",
       "8               https://tjournal.ru/p/lesya-echo-off  45124  \n",
       "9                https://tjournal.ru/p/stupid-quotes  27746  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!!   !!!!!!!!!! !!!!!!!!!!1 !!!!!!!!!!!!\n",
    "# Сначала почищу данные. Там, где не материалы редакции - мусор, на который твитов то почти и нет!\n",
    "news_info = news_info[ (news_info['type'] != \"TJ_C\")]\n",
    "len(news_info[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Мерджим дата фреймы\n",
    "df = news_info.merge(tweeter_data, on='url', left_index=True, right_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweeted_count</th>\n",
       "      <th>tw_id</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>2015-12-05 18:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[подписка, мобильные приложения, урбанизация, ...</td>\n",
       "      <td>Мнение: Приложения и интернет-сервисы убивают ...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/app-around-corner</td>\n",
       "      <td>6412</td>\n",
       "      <td>2015-12-06 12:01:57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>673427142642921472</td>\n",
       "      <td>8450</td>\n",
       "      <td>469</td>\n",
       "      <td>153</td>\n",
       "      <td>23</td>\n",
       "      <td>75097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments              date source  \\\n",
       "0        51  2015-12-05 18:45    NaN   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [подписка, мобильные приложения, урбанизация, ...   \n",
       "\n",
       "                                               title type  \\\n",
       "0  Мнение: Приложения и интернет-сервисы убивают ...   VC   \n",
       "\n",
       "                                 url  views           created_at  \\\n",
       "0  https://vc.ru/p/app-around-corner   6412  2015-12-06 12:01:57   \n",
       "\n",
       "   favorite_count  is_retweet  retweeted_count               tw_id  \\\n",
       "0               0           1                0  673427142642921472   \n",
       "\n",
       "   user_favourites_count  user_followers_count  user_friends_count  \\\n",
       "0                   8450                   469                 153   \n",
       "\n",
       "   user_listed_count  user_statuses_count  \n",
       "0                 23                75097  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_date_minutes(news_date, tweet_date):\n",
    "    news_date = datetime.strptime(news_date, '%Y-%m-%d %H:%M')\n",
    "    tweet_date = datetime.strptime(tweet_date, '%Y-%m-%d %H:%M:%S')\n",
    "    return int((tweet_date-news_date).total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# количество минут, с момента публикации записи, данного твита\n",
    "df[\"time_since_news\"] = df.apply(lambda s: diff_date_minutes(s[\"date\"], s[\"created_at\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_week_day(date):\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "    return date.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# индекс дня недели\n",
    "df[\"week_day_news\"] = df.date.apply(lambda s: get_week_day(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minutes_since_midnight(date):\n",
    "    midnight = date.split(\" \")[0] + \" 00:00\"\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "    midnight = datetime.strptime(midnight, '%Y-%m-%d %H:%M')\n",
    "    return int((date-midnight).total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сколько минут времени прошло с полуночи\n",
    "df[\"minutes_since_midnight\"] = df.date.apply(lambda s: get_minutes_since_midnight(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Агрегируем данные из твиттера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Время для вычисления независимых переменных\n",
    "FIRST_TIME = 10\n",
    "# Время для вычисления целевой функции\n",
    "LAST_TIME = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft_df = df[df[\"time_since_news\"] <= FIRST_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = ft_df.groupby(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем общее количество твиттов\n",
    "count_of_tweets = pd.DataFrame(grouped[\"url\"].count())\n",
    "count_of_tweets.columns = [\"first_time_tweet\"]\n",
    "count_of_tweets.reset_index(inplace=True)  \n",
    "df = pd.merge(df, count_of_tweets, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Считаем общую аудиторию\n",
    "follower_sum = pd.DataFrame(grouped[\"user_followers_count\"].sum())\n",
    "follower_sum.columns = [\"follower_sum\"]\n",
    "follower_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, follower_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем число ретвитов\n",
    "retweeted_count_sum = pd.DataFrame(grouped[\"retweeted_count\"].sum())\n",
    "retweeted_count_sum.columns = [\"retweeted_count_sum\"]\n",
    "retweeted_count_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, retweeted_count_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем число звездочек\n",
    "favorite_count_sum = pd.DataFrame(grouped[\"favorite_count\"].sum())\n",
    "favorite_count_sum.columns = [\"favorite_count_sum\"]\n",
    "favorite_count_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, favorite_count_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем общее число списков, в которых состоят сделавшие посты\n",
    "user_listed_count = pd.DataFrame(grouped[\"user_listed_count\"].sum())\n",
    "user_listed_count.columns = [\"user_listed_count_sum\"]\n",
    "user_listed_count.reset_index(inplace=True)  \n",
    "df = pd.merge(df, user_listed_count, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_df = df[df[\"time_since_news\"] <= LAST_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Выделяем значение целевой функции\n",
    "grouped = st_df.groupby(\"url\")\n",
    "count_of_tweets = pd.DataFrame(grouped[\"url\"].count())\n",
    "count_of_tweets.columns = [\"last_time_tweet\"]\n",
    "count_of_tweets.reset_index(inplace=True)  \n",
    "df = pd.merge(df, count_of_tweets, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREPARED_CSV = \"prepared_to_analys.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняемся\n",
    "df.to_csv(PREPARED_CSV, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# После первого запуска, через несколько дней, запускать только часть, которая находится под этим заголовком!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOURS = 8 # Количество часов от текущего момента. Текущее время - Hours часов - время последней собранной новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качаем новости с  2015-12-04 22:20  и  2015-12-04 21:23  по  2015-12-06 06:13\n",
      "Скачали  10  страниц\n",
      "https://roem.ru/rss/roem-all-news.xml\n",
      "http://lifenews.ru/xml/feed.xml\n",
      "http://www.forbes.ru/newrss.xml\n",
      "http://www.vesti.ru/vesti.rss\n",
      "http://lenta.ru/rss\n",
      "http://ria.ru/export/rss2/index.xml\n",
      "Собрано  394  новостей с RSS\n",
      "Собрано информация о 10  новостях\n",
      "Собрано информация о 20  новостях\n",
      "Собрано информация о 30  новостях\n",
      "Собрано информация о 40  новостях\n",
      "Собрано информация о 50  новостях\n",
      "Собрано информация о 60  новостях\n",
      "Собрано информация о 70  новостях\n",
      "Собрано информация о 80  новостях\n",
      "Собрано информация о 90  новостях\n",
      "Собрано информация о 100  новостях\n",
      "Собрано информация о 110  новостях\n",
      "Собрано информация о 120  новостях\n",
      "Собрано информация о 130  новостях\n",
      "Собрано информация о 140  новостях\n",
      "Собрано информация о 150  новостях\n",
      "Собрано информация о 160  новостях\n",
      "Собрано информация о 170  новостях\n",
      "Собрано информация о 180  новостях\n",
      "[{u'message': u'Rate limit exceeded', u'code': 88}]\n",
      "Спим 724 сек.\n",
      "Собрано информация о 190  новостях\n",
      "Собрано информация о 200  новостях\n",
      "Собрано информация о 210  новостях\n",
      "Собрано информация о 220  новостях\n",
      "Собрано информация о 230  новостях\n",
      "Собрано информация о 240  новостях\n",
      "Собрано информация о 250  новостях\n",
      "Собрано информация о 260  новостях\n",
      "Собрано информация о 270  новостях\n",
      "Собрано информация о 280  новостях\n",
      "Собрано информация о 290  новостях\n",
      "Собрано информация о 300  новостях\n",
      "Собрано информация о 310  новостях\n",
      "Собрано информация о 320  новостях\n",
      "Собрано информация о 330  новостях\n",
      "Собрано информация о 340  новостях\n",
      "Собрано информация о 350  новостях\n",
      "Собрано информация о 360  новостях\n",
      "[{u'message': u'Rate limit exceeded', u'code': 88}]\n",
      "Спим 696 сек.\n",
      "Собрано информация о 370  новостях\n",
      "Собрано информация о 380  новостях\n",
      "Собрано информация о 390  новостях\n",
      "Собрано информация о 400  новостях\n"
     ]
    }
   ],
   "source": [
    "def get_hours_ago(hours=3):\n",
    "    d = datetime.now() - timedelta(hours=hours)\n",
    "    d = str(d).split(\":\")\n",
    "    d = d[0]+\":\"+d[1]\n",
    "    return d\n",
    "\n",
    "\n",
    "def load_new_news(news_df, hours=3):\n",
    "    # Вычисляем самую молодую новость\n",
    "    tj_last_date = (news_df[news_df[\"type\"]==\"TJ_P\"][\"date\"]).max()\n",
    "    #tj_c_last_date = (news_df[news_df[\"type\"]==\"TJ_C\"][\"date\"]).max()\n",
    "    \n",
    "    #tj_last_date = max(tj_p_last_date, tj_c_last_date)\n",
    "    vc_last_date = (news_df[news_df[\"type\"]==\"VC\"][\"date\"]).max()\n",
    "    first_date = get_hours_ago(hours)\n",
    "    \n",
    "    \n",
    "    print \"Качаем новости с \", tj_last_date,\" и \", vc_last_date, \" по \", first_date\n",
    "    \n",
    "    tj_loader = TJLoader()\n",
    "    tj_pages = tj_loader.get_tj_news_info(min_index=0, count=4, first_date=first_date, last_date=tj_last_date)    \n",
    "    \n",
    "    vc_loader = VCLoader()\n",
    "    vc_pages = vc_loader.get_tj_news_info(first_date=first_date, last_date=vc_last_date)\n",
    "    \n",
    "    pages = vc_pages + tj_pages\n",
    "    pages\n",
    "    \n",
    "    return pages\n",
    "\n",
    "# Загружаем данные\n",
    "news_prev_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "twitter_prev_df = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")\n",
    "\n",
    "# Качаем новости с VC и TJ\n",
    "pages = load_new_news(news_prev_df, HOURS)\n",
    "# Качаем новости RSS\n",
    "rss_loader = RSSLoader()\n",
    "rss_pages = rss_loader.get_news_array()\n",
    "# Объединяем\n",
    "pages += rss_pages\n",
    "\n",
    "tw = TwitterLoader()\n",
    "tweets = tw.load_tweets_by_term(pages)\n",
    "\n",
    "# Объединяем новости с предыдущими\n",
    "news = pd.DataFrame(pages)\n",
    "news = (news.append(news_prev_df)).reset_index(drop=True)\n",
    "\n",
    "# Объединяем твиты с предыдущими\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df = (tweets_df.append(twitter_prev_df)).reset_index(drop=True)\n",
    "\n",
    "# Сохраняем\n",
    "tweets_df.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "news.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# УДАЛЯЕМ ПОВТОРЫ =((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено  384\n"
     ]
    }
   ],
   "source": [
    "# Сначала для твиттера\n",
    "tw_data = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")\n",
    "last_size = len(tw_data)\n",
    "dupl = tw_data[\"tw_id\"].duplicated()\n",
    "dupl = np.invert((dupl.as_matrix()))\n",
    "tw_data = tw_data[dupl]\n",
    "print \"Удалено \", last_size-len(tw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем!\n",
    "tw_data.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено  8\n"
     ]
    }
   ],
   "source": [
    "# Теперь для новостей\n",
    "news_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "last_size = len(news_df)\n",
    "dupl = news_df[\"url\"].duplicated()\n",
    "dupl = np.invert((dupl.as_matrix()))\n",
    "news_df = news_df[dupl]\n",
    "print \"Удалено \", last_size-len(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем\n",
    "news_df.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VC', 'TJ_P'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Здесь уже нет ничего хорошего. Уходи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news = news.append(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# читаем данные\n",
    "news_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "twitter_df = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# находим самую \"молодую новость\"\n",
    "news_df = news_df.sort_values(by=[\"date\"], ascending=False)\n",
    "tj_last_date = (news_df[news_df[\"type\"]==\"TJ_P\"][\"date\"]).max()\n",
    "vc_last_date = (news_df[news_df[\"type\"]==\"VC\"][\"date\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc_last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tj_news_info(self, min_index=1, count=30, first_date=\"2015-11-25 12:58\", last_date=\"2015-11-29 12:58\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# скачивае информацию о новостях\n",
    "loader = TJLoader()\n",
    "pages = loader.get_tj_news_info(min_index=0, count=30, first_date=\"2015-11-25 12:58\", last_date=\"2015-11-29 12:58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "news_df = news_df.append(pd.DataFrame(pages))\n",
    "news_df.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Скачиваем данные из твиттера\n",
    "tw = TwitterLoader()\n",
    "tweeter_data = tw.load_tweets_by_term(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tweeter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "twitter_df = twitter_df.append(pd.DataFrame(tweeter_data))\n",
    "twitter_df.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = datetime.now() - timedelta(hours=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = str(d).split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = requests.get(\"https://api.vc.ru/1/paper\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_req = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = html.parse(urlopen(\"https://vc.ru/p/interview-it\"))\n",
    "root = page.getroot()\n",
    "print root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = html.parse(urlopen(\"https://vc.ru/n/microsoft-store-russia\"))\n",
    "root = page.getroot()\n",
    "\n",
    "# заголовок\n",
    "title = root.find_class(\"b-article__head\")\n",
    "title = title[0].find(\"h1\").text\n",
    "print title\n",
    "\n",
    "# парсим количество просмотров\n",
    "view = root.get_element_by_id(\"hitsCount\").text\n",
    "view = view.replace(\" \", \"\")\n",
    "view = int(view)\n",
    "print view\n",
    "\n",
    "# Количество комментариев\n",
    "comments = root.find_class(\"ccount\")[0].text\n",
    "comment = int(comments.replace(\" \", \"\"))\n",
    "print comment\n",
    "\n",
    "tags = root.find_class(\"b-tags__tag\")\n",
    "tag_list = []\n",
    "for tag in tags:\n",
    "    tag_list.append(tag.text)\n",
    "    \n",
    "print tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VCLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc.get_link_info(\"https://vc.ru/n/microsoft-store-russia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc_dict = vc.get_tj_news_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопросы:\n",
    "\n",
    "1) Что делать с соурсе? Эти новости никто не репостит с TJournal, а от других источников их можно найти\n",
    "\n",
    "2) Урлы для других запросов на VC. Не хотелось бы их брудфорсить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
