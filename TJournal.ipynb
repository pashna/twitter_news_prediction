{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import lxml.html as html\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import tz\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TJLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = \"https://tjournal.ru/paper/page/{}\"\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        for i in range(count):\n",
    "            page = html.parse(urlopen(self._news_pages.format(i+min_index)))\n",
    "            divs = page.getroot().find_class('b-articles__b__title')\n",
    "\n",
    "            for div in divs:\n",
    "                links.append(div.getchildren()[1].get(\"href\"))\n",
    "\n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с tjournal, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__title\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"b-article__infoline__comments\")\n",
    "        comment = int(comments[0].find(\"b\").text.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-article__tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infoline__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "\n",
    "        return {\"title\": title, \"views\": view, \"comments\": comment, \"tags\": tag_list, \"date\": date}\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, last_news=\"\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :last_news: str, id последней новости, которую нужно скачать\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        for link in links:\n",
    "            link_info = self.get_link_info(link)\n",
    "            link_id = link.split(\"/\")[-1]\n",
    "            \n",
    "            # Если добрались до последней новости, которую хотим сохранить\n",
    "            if (link_id == last_news):\n",
    "                break\n",
    "            link_info[\"id\"] = link_id\n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterLoader:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        CONSUMER_KEY = 'BOuuaMDhNhm6yx0rzqK8bMsbI'\n",
    "        CONSUMER_SECRET = '3DybJwlkXd2vU6R385yLA8yJblYJltLtwojySD9AVs04ShauZ0'\n",
    "\n",
    "        ACCESS_TOKEN_KEY = '3712177576-of3jzZ8gNmlPDfPjPyR0Ljw1Ao2IXdTqX9dZGDZ'\n",
    "        ACCESS_TOKEN_SECRET = 'Ky7iKwByHNXX3UMfuMhv6UgVx2IhjLo3KmwpsBQz35wtG'\n",
    "\n",
    "        self.api = twitter.Api(consumer_key=CONSUMER_KEY,\n",
    "                  consumer_secret=CONSUMER_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN_KEY,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "        self._month_dict = {\"Jan\":\"1\", \"Feb\":\"2\", \"Mar\":\"3\", \"Apr\":\"4\", \"May\":\"5\", \"Jun\":\"6\", \"Jul\":\"7\", \"Aug\":\"8\", \"Sep\":\"9\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "\n",
    "        self._UTC_TIME_ZONE = tz.gettz('Europe/London')\n",
    "        self._MOSCOW_TIME_ZONE = tz.gettz('Europe/Moscow')\n",
    "        self._RATE_LIMIT = \"[{u'message': u'Rate limit exceeded', u'code': 88}]\"\n",
    "\n",
    "        self._news_uri = \"https://tjournal.ru/p/\"\n",
    "\n",
    "\n",
    "\n",
    "    def _parse_date(self, date):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата в формате твиттера - \"Sat Nov 21 17:00:29 +0000 2015\"\n",
    "        :return: str, дата в человеческом, но буржуйском формате, да еще и в Московском часовом поясе\n",
    "        \"\"\"\n",
    "        date_array = date.split(' ')\n",
    "        month = self._month_dict[date_array[1]]\n",
    "        day = int(date_array[2])\n",
    "        time = date_array[3]\n",
    "        year = date_array[5]\n",
    "\n",
    "        date = str(year)+\"-\"+str(month)+\"-\"+str(day)+\" \"+time\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        utc_date = date.replace(tzinfo=self._UTC_TIME_ZONE)\n",
    "        moscow_date = utc_date.astimezone(self._MOSCOW_TIME_ZONE)\n",
    "\n",
    "        return str(moscow_date).split(\"+\")[0]\n",
    "\n",
    "\n",
    "\n",
    "    def loadTweetWithLink(self, link, date):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, ключевое слово для поиска, вданном случае - ссылка на письмо\n",
    "        :param date: str, дата, до которой искать твиты\n",
    "        :return: список словариков с информацией о УНИКАЛЬНЫХ твитах по запросу link\n",
    "        \"\"\"\n",
    "        set_id = set()\n",
    "        tweet_list = []\n",
    "        result = self.api.GetSearch(term=link, until=date, count=100000)\n",
    "\n",
    "        for res in result:\n",
    "\n",
    "            tw_id = res.GetId()\n",
    "            # Если мы уже обрабатывали этот твит - идем дальше\n",
    "            if tw_id in set_id:\n",
    "                continue\n",
    "\n",
    "            retweeted_status = res.GetRetweeted_status()\n",
    "            # Если это не ретвит\n",
    "            if retweeted_status is None:\n",
    "                is_retweet = 0\n",
    "                retweeted_count = res.GetRetweetCount()\n",
    "                favorite_count = res.GetFavoriteCount()\n",
    "            else:\n",
    "                is_retweet = 1\n",
    "                retweeted_count = 0\n",
    "                favorite_count = 0\n",
    "            set_id.add(tw_id)\n",
    "\n",
    "            created_at = res.GetCreatedAt()\n",
    "            created_at = self._parse_date(created_at)\n",
    "\n",
    "            # Данные о пользователе\n",
    "            user = res.GetUser()\n",
    "            followers_count = user.followers_count\n",
    "            listed_count = user.listed_count\n",
    "            friends_count = user.friends_count\n",
    "            favourites_count = user.favourites_count\n",
    "            statuses_count = user.statuses_count\n",
    "\n",
    "\n",
    "            link = link.split(\"/\")[-1]\n",
    "\n",
    "            tw_dict= {\n",
    "                    \"id\": link,\n",
    "                    \"tw_id\":tw_id,\n",
    "                    \"retweeted_count\": retweeted_count,\n",
    "                    \"favorite_count\":favorite_count,\n",
    "                    \"is_retweet\": is_retweet,\n",
    "                    \"created_at\":created_at,\n",
    "                    \"user_followers_count\":followers_count,\n",
    "                    \"user_listed_count\": listed_count,\n",
    "                    \"user_friends_count\":friends_count,\n",
    "                    \"user_favourites_count\":favourites_count,\n",
    "                    \"user_statuses_count\":statuses_count\n",
    "                    }\n",
    "\n",
    "            tweet_list.append(tw_dict)\n",
    "\n",
    "        return tweet_list\n",
    "\n",
    "    def _get_next_date(self, date, days):\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата\n",
    "        :param days: int, количество дней\n",
    "        :return: возвращает дату через days-дней после date\n",
    "        \"\"\"\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "        date += timedelta(days=days)\n",
    "        return str(date).split(' ')[0]\n",
    "\n",
    "\n",
    "    def load_tweets_by_term(self, news_list, days_after_news=2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param news_list: list(str), список словариков с информацией о новости\n",
    "        :param days_after_news:  int, количество дней после публикации новости, до которой искать\n",
    "        \"\"\"\n",
    "        result_list = []\n",
    "        i = 0\n",
    "        for news in news_list:\n",
    "            tweets = []\n",
    "            try:\n",
    "                uri = self._news_uri + news[\"id\"]\n",
    "                until_date = self._get_next_date(news[\"date\"], days_after_news)\n",
    "                tweets = self.loadTweetWithLink(uri, until_date)\n",
    "            except twitter.error.TwitterError as ex:\n",
    "                print str(ex)\n",
    "                if str(ex) == self._RATE_LIMIT:\n",
    "                    sleep_time = self.api.GetSleepTime(\"search/tweets.json\") #??? Почему-то не работает\n",
    "                    print \"Спим {} сек.\".format(900)\n",
    "                    time.sleep(900+2)\n",
    "                    tweets = self.loadTweetWithLink(uri, until_date)\n",
    "\n",
    "            result_list+= tweets\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Собрано информация о\", i, \" новостях\"\n",
    "            \n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n",
      "Скачали  60  страниц\n"
     ]
    }
   ],
   "source": [
    "loader = TJLoader()\n",
    "pages = loader.get_tj_news_info(min_index=1, count=4, last_news=\"android-chrome-pacsec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news_info = pd.DataFrame(pages)\n",
    "news_info.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собрано информация о 10  новостях\n",
      "Собрано информация о 20  новостях\n",
      "Собрано информация о 30  новостях\n",
      "Собрано информация о 40  новостях\n",
      "Собрано информация о 50  новостях\n",
      "Собрано информация о 60  новостях\n"
     ]
    }
   ],
   "source": [
    "tw = TwitterLoader()\n",
    "tweeter_data = tw.load_tweets_by_term(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweeter_data = pd.DataFrame(tweeter_data)\n",
    "tweeter_data.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# После первого запуска, через несколько дней, запускать только часть, которая находится под этим заголовком!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT_NEWS_FILE = \"news.csv\"\n",
    "OUT_TWITTER_FILE = \"twitter.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# читаем данные\n",
    "news_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "twitter_df = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# находим самую \"молодую новость\"\n",
    "news_df = news_df.sort_values(by=[\"date\"], ascending=False)\n",
    "last_news = news_df[news_df.index==0][\"id\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# скачивае информацию о новостях\n",
    "loader = TJLoader()\n",
    "pages = loader.get_tj_news_info(min_index=1, count=6, last_news=last_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "news_df = news_df.append(pd.DataFrame(pages))\n",
    "news_df.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Скачиваем данные из твиттера\n",
    "tw = TwitterLoader()\n",
    "tweeter_data = tw.load_tweets_by_term(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tweeter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "twitter_df = twitter_df.append(pd.DataFrame(tweeter_data))\n",
    "twitter_df.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
