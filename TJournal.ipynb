{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import twitter\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import lxml.html as html\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import tz\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TJLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = [\"https://tjournal.ru/paper/page/{}\", \"https://tjournal.ru/club/news/recent/page/{}\"]\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        for news_page in self._news_pages:\n",
    "            \n",
    "            for i in range(count):\n",
    "                page = html.parse(urlopen(news_page.format(i+min_index)))\n",
    "                divs = page.getroot().find_class('b-articles__b__title')\n",
    "\n",
    "                for div in divs:\n",
    "                    links.append(div.getchildren()[1].get(\"href\"))\n",
    "\n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с tjournal, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__title\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"b-article__infoline__comments\")\n",
    "        comment = int(comments[0].find(\"b\").text.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-article__tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infoline__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "        # Первоисточник\n",
    "        source = root.find_class(\"b-article__link\")\n",
    "        if len(source) != 0:\n",
    "            source = source[0].getchildren()[0].getchildren()[1].getchildren()[0].text\n",
    "        else:\n",
    "            source = None\n",
    "        \n",
    "        # Type\n",
    "        if \"tjournal.ru/c/\" in link:\n",
    "            news_type = \"TJ_C\"\n",
    "        else:\n",
    "            news_type = \"TJ_P\"\n",
    "\n",
    "        return {\"title\": title, \"views\": view, \"comments\": comment, \"tags\": tag_list, \"date\": date, \"url\": link, \"type\": news_type, \"source\": source}\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, first_date=\"2010-01-01\", last_date=\"2017-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :last_news: str, id последней новости, которую нужно скачать\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        is_break = False\n",
    "        for link in links:\n",
    "            \n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"date\"] > first_date or link_info[\"date\"] < last_date:\n",
    "                continue\n",
    "    \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VCLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = \"https://api.vc.ru/1/paper\"\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        text = requests.get(self._news_pages).text\n",
    "        json_req = json.loads(text)\n",
    "    \n",
    "        for news in json_req:\n",
    "            links.append(news[\"url\"])\n",
    "\n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с vc, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__head\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"ccount\")[0].text\n",
    "        comment = int(comments.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infopanel__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "\n",
    "        return {\"title\": title, \"views\": view, \"comments\": comment, \"tags\": tag_list, \"date\": date, \"url\": link, \"type\": \"VC\"}\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, first_date=\"2010-01-01\", last_date=\"2017-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :first_date: str, дата и время первой (самой новой) новости\n",
    "        :last_date: str, дата и время последней(самой старой) новости\n",
    "        \n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        \n",
    "        for link in links:\n",
    "            \n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"date\"] > first_date or link_info[\"date\"] < last_date:\n",
    "                continue\n",
    "            \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterLoader:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        CONSUMER_KEY = 'BOuuaMDhNhm6yx0rzqK8bMsbI'\n",
    "        CONSUMER_SECRET = '3DybJwlkXd2vU6R385yLA8yJblYJltLtwojySD9AVs04ShauZ0'\n",
    "\n",
    "        ACCESS_TOKEN_KEY = '3712177576-of3jzZ8gNmlPDfPjPyR0Ljw1Ao2IXdTqX9dZGDZ'\n",
    "        ACCESS_TOKEN_SECRET = 'Ky7iKwByHNXX3UMfuMhv6UgVx2IhjLo3KmwpsBQz35wtG'\n",
    "\n",
    "        self.api = twitter.Api(consumer_key=CONSUMER_KEY,\n",
    "                  consumer_secret=CONSUMER_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN_KEY,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "        self._month_dict = {\"Jan\":\"1\", \"Feb\":\"2\", \"Mar\":\"3\", \"Apr\":\"4\", \"May\":\"5\", \"Jun\":\"6\", \"Jul\":\"7\", \"Aug\":\"8\", \"Sep\":\"9\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "\n",
    "        self._UTC_TIME_ZONE = tz.gettz('Europe/London')\n",
    "        self._MOSCOW_TIME_ZONE = tz.gettz('Europe/Moscow')\n",
    "        self._RATE_LIMIT = \"[{u'message': u'Rate limit exceeded', u'code': 88}]\"\n",
    "\n",
    "\n",
    "\n",
    "    def _parse_date(self, date):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата в формате твиттера - \"Sat Nov 21 17:00:29 +0000 2015\"\n",
    "        :return: str, дата в человеческом, но буржуйском формате, да еще и в Московском часовом поясе\n",
    "        \"\"\"\n",
    "        date_array = date.split(' ')\n",
    "        month = self._month_dict[date_array[1]]\n",
    "        day = int(date_array[2])\n",
    "        time = date_array[3]\n",
    "        year = date_array[5]\n",
    "\n",
    "        date = str(year)+\"-\"+str(month)+\"-\"+str(day)+\" \"+time\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        utc_date = date.replace(tzinfo=self._UTC_TIME_ZONE)\n",
    "        moscow_date = utc_date.astimezone(self._MOSCOW_TIME_ZONE)\n",
    "\n",
    "        return str(moscow_date).split(\"+\")[0]\n",
    "\n",
    "\n",
    "\n",
    "    def loadTweetWithLink(self, link, date):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, ключевое слово для поиска, вданном случае - ссылка на письмо\n",
    "        :param date: str, дата, до которой искать твиты\n",
    "        :return: список словариков с информацией о УНИКАЛЬНЫХ твитах по запросу link\n",
    "        \"\"\"\n",
    "        set_id = set()\n",
    "        tweet_list = []\n",
    "        result = self.api.GetSearch(term=link, until=date, count=100000)\n",
    "\n",
    "        for res in result:\n",
    "\n",
    "            tw_id = res.GetId()\n",
    "            # Если мы уже обрабатывали этот твит - идем дальше\n",
    "            if tw_id in set_id:\n",
    "                continue\n",
    "\n",
    "            retweeted_status = res.GetRetweeted_status()\n",
    "            # Если это не ретвит\n",
    "            if retweeted_status is None:\n",
    "                is_retweet = 0\n",
    "                retweeted_count = res.GetRetweetCount()\n",
    "                favorite_count = res.GetFavoriteCount()\n",
    "            else:\n",
    "                is_retweet = 1\n",
    "                retweeted_count = 0\n",
    "                favorite_count = 0\n",
    "            set_id.add(tw_id)\n",
    "\n",
    "            created_at = res.GetCreatedAt()\n",
    "            created_at = self._parse_date(created_at)\n",
    "\n",
    "            # Данные о пользователе\n",
    "            user = res.GetUser()\n",
    "            followers_count = user.followers_count\n",
    "            listed_count = user.listed_count\n",
    "            friends_count = user.friends_count\n",
    "            favourites_count = user.favourites_count\n",
    "            statuses_count = user.statuses_count\n",
    "\n",
    "\n",
    "            tw_dict= {\n",
    "                    \"url\": link,\n",
    "                    \"tw_id\":tw_id,\n",
    "                    \"retweeted_count\": retweeted_count,\n",
    "                    \"favorite_count\":favorite_count,\n",
    "                    \"is_retweet\": is_retweet,\n",
    "                    \"created_at\":created_at,\n",
    "                    \"user_followers_count\":followers_count,\n",
    "                    \"user_listed_count\": listed_count,\n",
    "                    \"user_friends_count\":friends_count,\n",
    "                    \"user_favourites_count\":favourites_count,\n",
    "                    \"user_statuses_count\":statuses_count\n",
    "                    }\n",
    "\n",
    "            tweet_list.append(tw_dict)\n",
    "\n",
    "        return tweet_list\n",
    "\n",
    "    def _get_next_date(self, date, days):\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата\n",
    "        :param days: int, количество дней\n",
    "        :return: возвращает дату через days-дней после date\n",
    "        \"\"\"\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "        date += timedelta(days=days)\n",
    "        return str(date).split(' ')[0]\n",
    "\n",
    "\n",
    "    def load_tweets_by_term(self, news_list, days_after_news=2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param news_list: list(str), список словариков с информацией о новости\n",
    "        :param days_after_news:  int, количество дней после публикации новости, до которой искать\n",
    "        \"\"\"\n",
    "        result_list = []\n",
    "        i = 0\n",
    "        for news in news_list:\n",
    "            tweets = []\n",
    "            try:\n",
    "                until_date = self._get_next_date(news[\"date\"], days_after_news)\n",
    "                tweets = self.loadTweetWithLink(news[\"url\"], until_date)\n",
    "            except twitter.error.TwitterError as ex:\n",
    "                print str(ex)\n",
    "                if str(ex) == self._RATE_LIMIT:\n",
    "                    sleep_time = self.api.GetSleepTime(\"search/tweets\") #??? Почему-то не работает\n",
    "                    print \"Спим {} сек.\".format(sleep_time)\n",
    "                    time.sleep(sleep_time+2)\n",
    "                    tweets = self.loadTweetWithLink(news[\"url\"], until_date)\n",
    "\n",
    "            result_list+= tweets\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Собрано информация о\", i, \" новостях\"\n",
    "            \n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n",
      "Скачали  60  страниц\n",
      "Скачали  70  страниц\n",
      "Скачали  80  страниц\n",
      "Скачали  90  страниц\n",
      "Скачали  100  страниц\n",
      "Скачали  110  страниц\n",
      "Скачали  120  страниц\n",
      "Скачали  130  страниц\n",
      "Скачали  140  страниц\n",
      "Скачали  150  страниц\n",
      "Скачали  160  страниц\n",
      "Скачали  170  страниц\n",
      "Скачали  180  страниц\n"
     ]
    }
   ],
   "source": [
    "loader = TJLoader()\n",
    "tj_pages = loader.get_tj_news_info(min_index=0, count=4, first_date=\"2015-11-25 14:00\", last_date=\"2015-11-17 10:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n"
     ]
    }
   ],
   "source": [
    "vc = VCLoader()\n",
    "vc_pages = vc.get_tj_news_info(first_date=\"2015-11-25 14:00\", last_date=\"2015-11-17 10:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = vc_pages + tj_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT_NEWS_FILE = \"news.csv\"\n",
    "OUT_TWITTER_FILE = \"twitter.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news_info = pd.DataFrame(pages)\n",
    "news_info.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-280-7b7d7ea17f4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitterLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtweeter_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_tweets_by_term\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-9e357b1e25b0>\u001b[0m in \u001b[0;36mload_tweets_by_term\u001b[1;34m(self, news_list, days_after_news)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0muntil_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_next_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdays_after_news\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                 \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadTweetWithLink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtwitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTwitterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-9e357b1e25b0>\u001b[0m in \u001b[0;36mloadTweetWithLink\u001b[1;34m(self, link, date)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mset_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mtweet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36mGetSearch\u001b[1;34m(self, term, geocode, since_id, max_id, until, count, lang, locale, result_type, include_entities)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;31m# Make and send requests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[0murl\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;34m'%s/search/tweets.json'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m     \u001b[0mjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RequestUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ParseAndCheckTwitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m_RequestUrl\u001b[1;34m(self, url, verb, data)\u001b[0m\n\u001b[0;32m   3600\u001b[0m           \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3601\u001b[0m           \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__auth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3602\u001b[1;33m           \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3603\u001b[0m         )\n\u001b[0;32m   3604\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;31m# By explicitly closing the session, we avoid leaving sockets open which\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# can trigger a ResourceWarning in some cases, and look like a memory leak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    466\u001b[0m         }\n\u001b[0;32m    467\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    368\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m                 )\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[0;32m    557\u001b[0m             httplib_response = self._make_request(conn, method, url,\n\u001b[0;32m    558\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m                                                   body=body, headers=headers)\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connection.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m                                     \u001b[0mca_cert_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                                     \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                                     ssl_version=resolved_ssl_version)\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.pyc\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_cert_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcertfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: OpenSSL with enabled SNI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    350\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                          _context=self)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_npn_protocols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpn_protocols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[0;32m    577\u001b[0m                         \u001b[1;31m# non-blocking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    806\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tw = TwitterLoader()\n",
    "tweeter_data = tw.load_tweets_by_term(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweeter_data = pd.DataFrame(tweeter_data)\n",
    "tweeter_data.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!!   !!!!!!!!!! !!!!!!!!!!1 !!!!!!!!!!!!\n",
    "# Сначала почищу данные. Там, где не материалы редакции - мусор, на который твитов то почти и нет!\n",
    "news_info = news_info[ (news_info['type'] == \"VC\") | (news_info[\"type\"] == \"TJ_P\")]\n",
    "len(news_info[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Мерджим дата фреймы\n",
    "df = news_info.merge(tweeter_data, on='url', left_index=False, right_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweeted_count</th>\n",
       "      <th>tw_id</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2015-11-25 12:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[роботы, тест, исследование, рекрутинг]</td>\n",
       "      <td>Роботы решают всё</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/hr-robots</td>\n",
       "      <td>729</td>\n",
       "      <td>2015-11-25 13:43:43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669466486570917889</td>\n",
       "      <td>1137</td>\n",
       "      <td>342</td>\n",
       "      <td>148</td>\n",
       "      <td>26</td>\n",
       "      <td>39371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>2015-11-25 12:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[роботы, тест, исследование, рекрутинг]</td>\n",
       "      <td>Роботы решают всё</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/hr-robots</td>\n",
       "      <td>729</td>\n",
       "      <td>2015-11-25 13:42:04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>669466071150305280</td>\n",
       "      <td>9</td>\n",
       "      <td>57750</td>\n",
       "      <td>6</td>\n",
       "      <td>666</td>\n",
       "      <td>15281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2015-11-25 11:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Gett позволит вызвать мастера для замены экран...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/gett-iphone</td>\n",
       "      <td>2105</td>\n",
       "      <td>2015-11-25 15:01:53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>669486160104824832</td>\n",
       "      <td>95</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2015-11-25 11:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Gett позволит вызвать мастера для замены экран...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/gett-iphone</td>\n",
       "      <td>2105</td>\n",
       "      <td>2015-11-25 13:52:09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>669468608909713408</td>\n",
       "      <td>4997</td>\n",
       "      <td>576</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>21629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments              date source                                     tags  \\\n",
       "0        15  2015-11-25 12:56    NaN  [роботы, тест, исследование, рекрутинг]   \n",
       "1        15  2015-11-25 12:56    NaN  [роботы, тест, исследование, рекрутинг]   \n",
       "2        18  2015-11-25 11:57    NaN                                       []   \n",
       "3        18  2015-11-25 11:57    NaN                                       []   \n",
       "\n",
       "                                               title type  \\\n",
       "0                                  Роботы решают всё   VC   \n",
       "1                                  Роботы решают всё   VC   \n",
       "2  Gett позволит вызвать мастера для замены экран...   VC   \n",
       "3  Gett позволит вызвать мастера для замены экран...   VC   \n",
       "\n",
       "                           url  views           created_at  favorite_count  \\\n",
       "0    https://vc.ru/p/hr-robots    729  2015-11-25 13:43:43               0   \n",
       "1    https://vc.ru/p/hr-robots    729  2015-11-25 13:42:04               4   \n",
       "2  https://vc.ru/n/gett-iphone   2105  2015-11-25 15:01:53               0   \n",
       "3  https://vc.ru/n/gett-iphone   2105  2015-11-25 13:52:09               0   \n",
       "\n",
       "   is_retweet  retweeted_count               tw_id  user_favourites_count  \\\n",
       "0           1                0  669466486570917889                   1137   \n",
       "1           0                1  669466071150305280                      9   \n",
       "2           1                0  669486160104824832                     95   \n",
       "3           0                0  669468608909713408                   4997   \n",
       "\n",
       "   user_followers_count  user_friends_count  user_listed_count  \\\n",
       "0                   342                 148                 26   \n",
       "1                 57750                   6                666   \n",
       "2                    13                  28                  0   \n",
       "3                   576                  58                 46   \n",
       "\n",
       "   user_statuses_count  \n",
       "0                39371  \n",
       "1                15281  \n",
       "2                 3903  \n",
       "3                21629  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_date_minutes(news_date, tweet_date):\n",
    "    news_date = datetime.strptime(news_date, '%Y-%m-%d %H:%M')\n",
    "    tweet_date = datetime.strptime(tweet_date, '%Y-%m-%d %H:%M:%S')\n",
    "    return int((tweet_date-news_date).total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# количество минут, с момента публикации записи, данного твита\n",
    "df[\"time_since_news\"] = df.apply(lambda s: diff_date_minutes(s[\"date\"], s[\"created_at\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_week_day(date):\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "    return date.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# индекс дня недели\n",
    "df[\"week_day_news\"] = df.date.apply(lambda s: get_week_day(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minutes_since_midnight(date):\n",
    "    midnight = date.split(\" \")[0] + \" 00:00\"\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "    midnight = datetime.strptime(midnight, '%Y-%m-%d %H:%M')\n",
    "    return int((date-midnight).total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сколько минут времени прошло с полуночи\n",
    "df[\"minutes_since_midnight\"] = df.date.apply(lambda s: get_minutes_since_midnight(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Агрегируем данные из твиттера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Время для вычисления независимых переменных\n",
    "FIRST_TIME = 10\n",
    "# Время для вычисления целевой функции\n",
    "LAST_TIME = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft_df = df[df[\"time_since_news\"] <= FIRST_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = ft_df.groupby(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем общее количество твиттов\n",
    "count_of_tweets = pd.DataFrame(grouped[\"url\"].count())\n",
    "count_of_tweets.columns = [\"first_time_tweet\"]\n",
    "count_of_tweets.reset_index(inplace=True)  \n",
    "df = pd.merge(df, count_of_tweets, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Считаем общую аудиторию\n",
    "follower_sum = pd.DataFrame(grouped[\"user_followers_count\"].sum())\n",
    "follower_sum.columns = [\"follower_sum\"]\n",
    "follower_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, follower_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем число ретвитов\n",
    "retweeted_count_sum = pd.DataFrame(grouped[\"retweeted_count\"].sum())\n",
    "retweeted_count_sum.columns = [\"retweeted_count_sum\"]\n",
    "retweeted_count_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, retweeted_count_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем число звездочек\n",
    "favorite_count_sum = pd.DataFrame(grouped[\"favorite_count\"].sum())\n",
    "favorite_count_sum.columns = [\"favorite_count_sum\"]\n",
    "favorite_count_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, favorite_count_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем общее число списков, в которых состоят сделавшие посты\n",
    "user_listed_count = pd.DataFrame(grouped[\"user_listed_count\"].sum())\n",
    "user_listed_count.columns = [\"favorite_count\"]\n",
    "user_listed_count.reset_index(inplace=True)  \n",
    "df = pd.merge(df, user_listed_count, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_df = df[df[\"time_since_news\"] <= LAST_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Выделяем значение целевой функции\n",
    "grouped = st_df.groupby(\"url\")\n",
    "count_of_tweets = pd.DataFrame(grouped[\"url\"].count())\n",
    "count_of_tweets.columns = [\"last_time_tweet\"]\n",
    "count_of_tweets.reset_index(inplace=True)  \n",
    "df = pd.merge(df, count_of_tweets, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняемся\n",
    "df.to_csv(\"prepared_to_analys.csv\", sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналитим "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[[\"first_time_tweet\",\"last_time_tweet\"]].drop_duplicates().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count_x</th>\n",
       "      <th>...</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>time_since_news</th>\n",
       "      <th>week_day_news</th>\n",
       "      <th>minutes_since_midnight</th>\n",
       "      <th>first_time_tweet</th>\n",
       "      <th>follower_sum</th>\n",
       "      <th>retweeted_count_sum</th>\n",
       "      <th>favorite_count_sum</th>\n",
       "      <th>favorite_count_y</th>\n",
       "      <th>last_time_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>15</td>\n",
       "      <td>2015-11-25 12:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[роботы, тест, исследование, рекрутинг]</td>\n",
       "      <td>Роботы решают всё</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/hr-robots</td>\n",
       "      <td>729</td>\n",
       "      <td>2015-11-25 13:43:43</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39371</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>15</td>\n",
       "      <td>2015-11-25 12:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[роботы, тест, исследование, рекрутинг]</td>\n",
       "      <td>Роботы решают всё</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/hr-robots</td>\n",
       "      <td>729</td>\n",
       "      <td>2015-11-25 13:42:04</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15281</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>18</td>\n",
       "      <td>2015-11-25 11:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Gett позволит вызвать мастера для замены экран...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/gett-iphone</td>\n",
       "      <td>2105</td>\n",
       "      <td>2015-11-25 15:01:53</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3903</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>57799</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>18</td>\n",
       "      <td>2015-11-25 11:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Gett позволит вызвать мастера для замены экран...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/gett-iphone</td>\n",
       "      <td>2105</td>\n",
       "      <td>2015-11-25 13:52:09</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21629</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>57799</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>18</td>\n",
       "      <td>2015-11-25 11:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Gett позволит вызвать мастера для замены экран...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/gett-iphone</td>\n",
       "      <td>2105</td>\n",
       "      <td>2015-11-25 13:49:20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>714</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>57799</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    comments              date source  \\\n",
       "69        15  2015-11-25 12:56    NaN   \n",
       "69        15  2015-11-25 12:56    NaN   \n",
       "62        18  2015-11-25 11:57    NaN   \n",
       "62        18  2015-11-25 11:57    NaN   \n",
       "62        18  2015-11-25 11:57    NaN   \n",
       "\n",
       "                                       tags  \\\n",
       "69  [роботы, тест, исследование, рекрутинг]   \n",
       "69  [роботы, тест, исследование, рекрутинг]   \n",
       "62                                       []   \n",
       "62                                       []   \n",
       "62                                       []   \n",
       "\n",
       "                                                title type  \\\n",
       "69                                  Роботы решают всё   VC   \n",
       "69                                  Роботы решают всё   VC   \n",
       "62  Gett позволит вызвать мастера для замены экран...   VC   \n",
       "62  Gett позволит вызвать мастера для замены экран...   VC   \n",
       "62  Gett позволит вызвать мастера для замены экран...   VC   \n",
       "\n",
       "                            url  views           created_at  favorite_count_x  \\\n",
       "69    https://vc.ru/p/hr-robots    729  2015-11-25 13:43:43                 0   \n",
       "69    https://vc.ru/p/hr-robots    729  2015-11-25 13:42:04                 4   \n",
       "62  https://vc.ru/n/gett-iphone   2105  2015-11-25 15:01:53                 0   \n",
       "62  https://vc.ru/n/gett-iphone   2105  2015-11-25 13:52:09                 0   \n",
       "62  https://vc.ru/n/gett-iphone   2105  2015-11-25 13:49:20                 0   \n",
       "\n",
       "         ...         user_statuses_count  time_since_news  week_day_news  \\\n",
       "69       ...                       39371               47              2   \n",
       "69       ...                       15281               46              2   \n",
       "62       ...                        3903              184              2   \n",
       "62       ...                       21629              115              2   \n",
       "62       ...                         714              112              2   \n",
       "\n",
       "    minutes_since_midnight  first_time_tweet  follower_sum  \\\n",
       "69                     776               NaN           NaN   \n",
       "69                     776               NaN           NaN   \n",
       "62                     717                 2         57799   \n",
       "62                     717                 2         57799   \n",
       "62                     717                 2         57799   \n",
       "\n",
       "    retweeted_count_sum  favorite_count_sum  favorite_count_y  last_time_tweet  \n",
       "69                  NaN                 NaN               NaN              NaN  \n",
       "69                  NaN                 NaN               NaN              NaN  \n",
       "62                    2                   2               669                2  \n",
       "62                    2                   2               669                2  \n",
       "62                    2                   2               669                2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаляем лишние столбцы\n",
    "major_features = [\"url\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# После первого запуска, через несколько дней, запускать только часть, которая находится под этим заголовком!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# читаем данные\n",
    "news_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "twitter_df = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# находим самую \"молодую новость\"\n",
    "news_df = news_df.sort_values(by=[\"date\"], ascending=False)\n",
    "last_news = news_df[news_df.index==0][\"url\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# скачивае информацию о новостях\n",
    "loader = TJLoader()\n",
    "pages = loader.get_tj_news_info(min_index=1, count=6, last_news=last_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "news_df = news_df.append(pd.DataFrame(pages))\n",
    "news_df.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Скачиваем данные из твиттера\n",
    "tw = TwitterLoader()\n",
    "tweeter_data = tw.load_tweets_by_term(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tweeter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "twitter_df = twitter_df.append(pd.DataFrame(tweeter_data))\n",
    "twitter_df.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = requests.get(\"https://api.vc.ru/1/paper\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_req = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xd0\\x9f\\xd0\\x9e\\xd0\\xa6\\xd0\\x95\\xd0\\x9b\\xd0\\xa3\\xd0\\x99'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element html at 0x7f8cf07d6628>\n"
     ]
    }
   ],
   "source": [
    "page = html.parse(urlopen(\"https://vc.ru/p/interview-it\"))\n",
    "root = page.getroot()\n",
    "print root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft открыла собственный онлайн-магазин в России\n",
      "5865\n",
      "19\n",
      "['microsoft', u'\\u0438\\u043d\\u0442\\u0435\\u0440\\u043d\\u0435\\u0442-\\u043c\\u0430\\u0433\\u0430\\u0437\\u0438\\u043d']\n"
     ]
    }
   ],
   "source": [
    "page = html.parse(urlopen(\"https://vc.ru/n/microsoft-store-russia\"))\n",
    "root = page.getroot()\n",
    "\n",
    "# заголовок\n",
    "title = root.find_class(\"b-article__head\")\n",
    "title = title[0].find(\"h1\").text\n",
    "print title\n",
    "\n",
    "# парсим количество просмотров\n",
    "view = root.get_element_by_id(\"hitsCount\").text\n",
    "view = view.replace(\" \", \"\")\n",
    "view = int(view)\n",
    "print view\n",
    "\n",
    "# Количество комментариев\n",
    "comments = root.find_class(\"ccount\")[0].text\n",
    "comment = int(comments.replace(\" \", \"\"))\n",
    "print comment\n",
    "\n",
    "tags = root.find_class(\"b-tags__tag\")\n",
    "tag_list = []\n",
    "for tag in tags:\n",
    "    tag_list.append(tag.text)\n",
    "    \n",
    "print tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какие вы любите сэндвичи\n"
     ]
    }
   ],
   "source": [
    "print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VCLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comments': 19,\n",
       " 'date': u'2015-11-24 22:13',\n",
       " 'tags': ['microsoft',\n",
       "  u'\\u0438\\u043d\\u0442\\u0435\\u0440\\u043d\\u0435\\u0442-\\u043c\\u0430\\u0433\\u0430\\u0437\\u0438\\u043d'],\n",
       " 'title': u'Microsoft \\u043e\\u0442\\u043a\\u0440\\u044b\\u043b\\u0430 \\u0441\\u043e\\u0431\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u044b\\u0439 \\u043e\\u043d\\u043b\\u0430\\u0439\\u043d-\\u043c\\u0430\\u0433\\u0430\\u0437\\u0438\\u043d \\u0432 \\u0420\\u043e\\u0441\\u0441\\u0438\\u0438',\n",
       " 'views': 5915}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.get_link_info(\"https://vc.ru/n/microsoft-store-russia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n"
     ]
    }
   ],
   "source": [
    "vc_dict = vc.get_tj_news_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопросы:\n",
    "1) Что делать с соурсе? Эти новости никто не репостит с TJournal, а от других источников их можно найти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
