{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import twitter\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import lxml.html as html\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import tz\n",
    "import time\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT_NEWS_FILE = \"news.csv\"\n",
    "OUT_TWITTER_FILE = \"twitter.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TJLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = [\"https://tjournal.ru/paper/page/{}\"]#, \"https://tjournal.ru/club/news/recent/page/{}\"]\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        for news_page in self._news_pages:\n",
    "            \n",
    "            for i in range(count):\n",
    "                page = html.parse(urlopen(news_page.format(i+min_index)))\n",
    "                divs = page.getroot().find_class('b-articles__b__title')\n",
    "\n",
    "                for div in divs:\n",
    "                    links.append(div.getchildren()[1].get(\"href\"))\n",
    "                    \n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с tjournal, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__title\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"b-article__infoline__comments\")\n",
    "        comment = int(comments[0].find(\"b\").text.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-article__tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infoline__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "        # Первоисточник\n",
    "        source = root.find_class(\"b-article__link\")\n",
    "        if len(source) != 0:\n",
    "            source = source[0].getchildren()[0].getchildren()[1].getchildren()[0].text\n",
    "        else:\n",
    "            source = None\n",
    "        \n",
    "        # Type\n",
    "        if \"tjournal.ru/c/\" in link:\n",
    "            news_type = \"TJ_C\"\n",
    "        else:\n",
    "            news_type = \"TJ_P\"\n",
    "            \n",
    "        return {\n",
    "            \"url\": link, \n",
    "            \"title\": title, \n",
    "            \"views\": view, \n",
    "            \"comments\": comment, \n",
    "            \"tags\": tag_list, \n",
    "            \"date\": date, \n",
    "            \"type\": news_type, \n",
    "            \"source\": source}\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, first_date=\"2017-01-01\", last_date=\"2010-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :first_date: время первой новости, которую мы скачаем\n",
    "        :last_date: время последней новости, которую мы скачаем\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        is_break = False\n",
    "        for link in links:\n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"date\"] > first_date or link_info[\"date\"] < last_date:\n",
    "                continue\n",
    "    \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VCLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._news_pages = \"https://api.vc.ru/1/paper\"\n",
    "        self._month_map = {u\"января\":\"01\", u\"февраля\":\"02\", u\"марта\":\"03\", u\"апреля\":\"04\", u\"мая\":\"05\", u\"июня\":\"06\", u\"июля\":\"07\", u\"августа\":\"08\", u\"сентября\":\"09\", u\"октября\":\"10\", u\"ноября\":\"11\", u\"декабря\":\"12\"}\n",
    "\n",
    "    def get_news_uri(self, min_index=10, count=30):\n",
    "        \"\"\"\n",
    "\n",
    "        :param min_index: int, индекс страницы, с которой нужно начать поиск\n",
    "        :param count: int, количество страниц, которые нужно скачать\n",
    "        :return: list. список ссылок на новости\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        text = requests.get(self._news_pages).text\n",
    "        json_req = json.loads(text)\n",
    "    \n",
    "        for news in json_req:\n",
    "            links.append(news[\"url\"])\n",
    "\n",
    "        return links\n",
    "\n",
    "    \n",
    "    def _parse_date(self, date):\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date = date.split(\" \")\n",
    "        \n",
    "        converted_date = date[2]\n",
    "        converted_date +=\"-\"+self._month_map[date[1]]\n",
    "        converted_date +=\"-\"+date[0]\n",
    "        \n",
    "        converted_date +=\" \"+date[3]\n",
    "        \n",
    "        return converted_date\n",
    "        \n",
    "\n",
    "    def get_link_info(self, link):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, url страницы с vc, для которой нужно собрать информацию\n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        page = html.parse(urlopen(link))\n",
    "        root = page.getroot()\n",
    "\n",
    "        # заголовок\n",
    "        title = root.find_class(\"b-article__head\")\n",
    "        title = title[0].find(\"h1\").text\n",
    "\n",
    "        # парсим количество просмотров\n",
    "        view = root.get_element_by_id(\"hitsCount\").text\n",
    "        view = view.replace(\" \", \"\")\n",
    "        view = int(view)\n",
    "\n",
    "        # Количество комментариев\n",
    "        comments = root.find_class(\"ccount\")[0].text\n",
    "        comment = int(comments.replace(\" \", \"\"))\n",
    "\n",
    "        # Теги\n",
    "        tags = root.find_class(\"b-tags__tag\")\n",
    "        tag_list = []\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "        \n",
    "        # Дата\n",
    "        date = root.find_class(\"b-article__infopanel__date\")\n",
    "        date = self._parse_date(date[0].text)\n",
    "        \n",
    "\n",
    "        return {\"title\": title, \"views\": view, \"comments\": comment, \"tags\": tag_list, \"date\": date, \"url\": link, \"type\": \"VC\"}\n",
    "\n",
    "\n",
    "    def get_tj_news_info(self, min_index=1, count=30, first_date=\"2010-01-01\", last_date=\"2017-01-01\"):\n",
    "        \"\"\"\n",
    "        :param min_index: int, индекс минимальной страницы, откуда начинаем поиск\n",
    "        :param count: int, количество страниц, по которым ищем\n",
    "        :first_date: str, дата и время первой (самой новой) новости\n",
    "        :last_date: str, дата и время последней(самой старой) новости\n",
    "        \n",
    "        :return: dict с данными со страницы\n",
    "        \"\"\"\n",
    "        links = self.get_news_uri(min_index=min_index, count=count)\n",
    "        link_info_list = []\n",
    "        i = 0\n",
    "        \n",
    "        for link in links:\n",
    "            \n",
    "            link_info = self.get_link_info(link)\n",
    "            # Если заданное время не подходит\n",
    "            if link_info[\"date\"] > first_date or link_info[\"date\"] < last_date:\n",
    "                continue\n",
    "            \n",
    "            link_info_list.append(link_info)\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Скачали \", i, \" страниц\"\n",
    "\n",
    "        return link_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RSSLoader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self._pages = [\"https://roem.ru/rss/roem-all-news.xml\", \"http://lifenews.ru/xml/feed.xml\", \"http://www.forbes.ru/newrss.xml\", \"http://rg.ru/xml/index.xml\", \"http://www.vesti.ru/vesti.rss\", \"http://lenta.ru/rss\", \"http://ria.ru/export/rss2/index.xml\"]\n",
    "        self._pages = [\"https://roem.ru/rss/roem-all-news.xml\", \"http://lifenews.ru/xml/feed.xml\", \"http://www.forbes.ru/newrss.xml\", \"http://www.vesti.ru/vesti.rss\", \"http://lenta.ru/rss\", \"http://ria.ru/export/rss2/index.xml\"]\n",
    "        self._month_dict = {\"Jan\":\"1\", \"Feb\":\"2\", \"Mar\":\"3\", \"Apr\":\"4\", \"May\":\"5\", \"Jun\":\"6\", \"Jul\":\"7\", \"Aug\":\"8\", \"Sep\":\"9\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "        \n",
    "        \n",
    "        self._UTC_TIME_ZONE = tz.gettz('Europe/London')\n",
    "        self._MOSCOW_TIME_ZONE = tz.gettz('Europe/Moscow')\n",
    "        self._RATE_LIMIT = \"[{u'message': u'Rate limit exceeded', u'code': 88}]\"\n",
    "        \n",
    "        \n",
    "    def _parse_date(self, date):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата в формате - \"Fri, 04 Dec 2015 14:45:39 +0000\"\n",
    "        :return: str, дата в человеческом, но буржуйском формате, да еще и в Московском часовом поясе\n",
    "        \"\"\"\n",
    "        timezone = date.split(\"+\")[1]\n",
    "        date = date.replace(\",\", \"\")\n",
    "        date_array = date.split(' ')\n",
    "        \n",
    "        time = date_array[4]\n",
    "        day = int(date_array[1])\n",
    "        month = self._month_dict[date_array[2]]\n",
    "        year = date_array[3]\n",
    "\n",
    "        date = str(year)+\"-\"+str(month)+\"-\"+str(day)+\" \"+time\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        if (timezone != \"0300\"):\n",
    "            utc_date = date.replace(tzinfo=self._UTC_TIME_ZONE)\n",
    "            date = utc_date.astimezone(self._MOSCOW_TIME_ZONE)\n",
    "\n",
    "        # Обрезаем зону\n",
    "        date = str(date).split(\"+\")[0]\n",
    "        \n",
    "        # Обрезаем секунды\n",
    "        splited = date.split(\":\")\n",
    "        date = splited[0]+\":\"+splited[1]\n",
    "        return date\n",
    "    \n",
    "    \n",
    "    def _get_type(self, url):\n",
    "        url = url.replace(\"www\", \"\")\n",
    "        url = url.split(\"://\")[1]\n",
    "        url = url.split(\"/\")[0]\n",
    "        return url\n",
    "        \n",
    "    \n",
    "    def _get_hours_until_now(self, date):\n",
    "        news_date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "        now = datetime.today()\n",
    "        return float((now-news_date).total_seconds()/3600)\n",
    "        \n",
    "    def get_news_array(self, hour=8):\n",
    "        \"\"\"\n",
    "        hour: int, время последней новости\n",
    "        \"\"\"\n",
    "        news_array = []\n",
    "        for url in self._pages:\n",
    "            news_type = self._get_type(url)\n",
    "            print url\n",
    "            \n",
    "            tree = ET.ElementTree(file=urlopen(url))\n",
    "            root = tree.getroot()\n",
    "            for i in root.iter('item'):\n",
    "                link = i.find('link').text\n",
    "                title = i.find('title').text\n",
    "                date_ = i.find('pubDate').text\n",
    "                date = self._parse_date(date_)\n",
    "                \n",
    "                news_info =  {\n",
    "                    \"title\": title,\n",
    "                    \"date\": date, \n",
    "                    \"url\": link, \n",
    "                    \"type\": news_type\n",
    "                }\n",
    "                \n",
    "                if self._get_hours_until_now(date) >= hour:\n",
    "                    news_array.append(news_info)\n",
    "                \n",
    "            \n",
    "        print \"Собрано \", len(news_array), \" новостей с RSS\"\n",
    "        return news_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterLoader:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        CONSUMER_KEY = 'BOuuaMDhNhm6yx0rzqK8bMsbI'\n",
    "        CONSUMER_SECRET = '3DybJwlkXd2vU6R385yLA8yJblYJltLtwojySD9AVs04ShauZ0'\n",
    "\n",
    "        ACCESS_TOKEN_KEY = '3712177576-of3jzZ8gNmlPDfPjPyR0Ljw1Ao2IXdTqX9dZGDZ'\n",
    "        ACCESS_TOKEN_SECRET = 'Ky7iKwByHNXX3UMfuMhv6UgVx2IhjLo3KmwpsBQz35wtG'\n",
    "\n",
    "        self.api = twitter.Api(consumer_key=CONSUMER_KEY,\n",
    "                  consumer_secret=CONSUMER_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN_KEY,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "        self._month_dict = {\"Jan\":\"1\", \"Feb\":\"2\", \"Mar\":\"3\", \"Apr\":\"4\", \"May\":\"5\", \"Jun\":\"6\", \"Jul\":\"7\", \"Aug\":\"8\", \"Sep\":\"9\", \"Oct\":\"10\", \"Nov\":\"11\", \"Dec\":\"12\"}\n",
    "\n",
    "        self._UTC_TIME_ZONE = tz.gettz('Europe/London')\n",
    "        self._MOSCOW_TIME_ZONE = tz.gettz('Europe/Moscow')\n",
    "        self._RATE_LIMIT = \"[{u'message': u'Rate limit exceeded', u'code': 88}]\"\n",
    "\n",
    "\n",
    "\n",
    "    def _parse_date(self, date):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата в формате твиттера - \"Sat Nov 21 17:00:29 +0000 2015\"\n",
    "        :return: str, дата в человеческом, но буржуйском формате, да еще и в Московском часовом поясе\n",
    "        \"\"\"\n",
    "        date_array = date.split(' ')\n",
    "        month = self._month_dict[date_array[1]]\n",
    "        day = int(date_array[2])\n",
    "        time = date_array[3]\n",
    "        year = date_array[5]\n",
    "\n",
    "        date = str(year)+\"-\"+str(month)+\"-\"+str(day)+\" \"+time\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        utc_date = date.replace(tzinfo=self._UTC_TIME_ZONE)\n",
    "        moscow_date = utc_date.astimezone(self._MOSCOW_TIME_ZONE)\n",
    "\n",
    "        return str(moscow_date).split(\"+\")[0]\n",
    "\n",
    "\n",
    "\n",
    "    def loadTweetWithLink(self, link, date):\n",
    "        \"\"\"\n",
    "\n",
    "        :param link: str, ключевое слово для поиска, вданном случае - ссылка на письмо\n",
    "        :param date: str, дата, до которой искать твиты\n",
    "        :return: список словариков с информацией о УНИКАЛЬНЫХ твитах по запросу link\n",
    "        \"\"\"\n",
    "        set_id = set()\n",
    "        tweet_list = []\n",
    "        result = self.api.GetSearch(term=link, until=date, count=100000)\n",
    "\n",
    "        for res in result:\n",
    "\n",
    "            tw_id = res.GetId()\n",
    "            # Если мы уже обрабатывали этот твит - идем дальше\n",
    "            if tw_id in set_id:\n",
    "                continue\n",
    "\n",
    "            retweeted_status = res.GetRetweeted_status()\n",
    "            # Если это не ретвит\n",
    "            if retweeted_status is None:\n",
    "                is_retweet = 0\n",
    "                retweeted_count = res.GetRetweetCount()\n",
    "                favorite_count = res.GetFavoriteCount()\n",
    "            else:\n",
    "                is_retweet = 1\n",
    "                retweeted_count = 0\n",
    "                favorite_count = 0\n",
    "            set_id.add(tw_id)\n",
    "\n",
    "            created_at = res.GetCreatedAt()\n",
    "            created_at = self._parse_date(created_at)\n",
    "\n",
    "            # Данные о пользователе\n",
    "            user = res.GetUser()\n",
    "            followers_count = user.followers_count\n",
    "            listed_count = user.listed_count\n",
    "            friends_count = user.friends_count\n",
    "            favourites_count = user.favourites_count\n",
    "            statuses_count = user.statuses_count\n",
    "\n",
    "\n",
    "            tw_dict= {\n",
    "                    \"url\": link,\n",
    "                    \"tw_id\":tw_id,\n",
    "                    \"retweeted_count\": retweeted_count,\n",
    "                    \"favorite_count\":favorite_count,\n",
    "                    \"is_retweet\": is_retweet,\n",
    "                    \"created_at\":created_at,\n",
    "                    \"user_followers_count\":followers_count,\n",
    "                    \"user_listed_count\": listed_count,\n",
    "                    \"user_friends_count\":friends_count,\n",
    "                    \"user_favourites_count\":favourites_count,\n",
    "                    \"user_statuses_count\":statuses_count\n",
    "                    }\n",
    "\n",
    "            tweet_list.append(tw_dict)\n",
    "\n",
    "        return tweet_list\n",
    "\n",
    "    def _get_next_date(self, date, days):\n",
    "        \"\"\"\n",
    "\n",
    "        :param date: str, дата\n",
    "        :param days: int, количество дней\n",
    "        :return: возвращает дату через days-дней после date\n",
    "        \"\"\"\n",
    "        date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "        date += timedelta(days=days)\n",
    "        return str(date).split(' ')[0]\n",
    "\n",
    "\n",
    "    def load_tweets_by_term(self, news_list, days_after_news=2):\n",
    "        \"\"\"\n",
    "\n",
    "        :param news_list: list(str), список словариков с информацией о новости\n",
    "        :param days_after_news:  int, количество дней после публикации новости, до которой искать\n",
    "        \"\"\"\n",
    "        result_list = []\n",
    "        i = 0\n",
    "        for news in news_list:\n",
    "            tweets = []\n",
    "            try:\n",
    "                until_date = self._get_next_date(news[\"date\"], days_after_news)\n",
    "                tweets = self.loadTweetWithLink(news[\"url\"], until_date)\n",
    "            except twitter.error.TwitterError as ex:\n",
    "                print str(ex)\n",
    "                if str(ex) == self._RATE_LIMIT:\n",
    "                    sleep_time = self.api.GetSleepTime(\"search/tweets\") #??? Почему-то не работает\n",
    "                    print \"Спим {} сек.\".format(sleep_time)\n",
    "                    time.sleep(sleep_time+2)\n",
    "                    tweets = self.loadTweetWithLink(news[\"url\"], until_date)\n",
    "\n",
    "            result_list+= tweets\n",
    "            \n",
    "            i+=1\n",
    "            if i%10 == 0:\n",
    "                print \"Собрано информация о\", i, \" новостях\"\n",
    "            \n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Подготавливаем  данные для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news_info = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "tweeter_data = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-12-04 21:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[uber]</td>\n",
       "      <td>Украинское министерство инфраструктуры анонсир...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/uber-ukraine</td>\n",
       "      <td>2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>2015-12-04 22:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[научные исследования, британские учёные, глуп...</td>\n",
       "      <td>Глупость любителей «глубокомысленных» цитат по...</td>\n",
       "      <td>TJ_P</td>\n",
       "      <td>https://tjournal.ru/p/stupid-quotes</td>\n",
       "      <td>18778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-04 18:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Samsung выплатит Apple $548 млн за нарушение п...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/no-one-simply-court</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2015-12-04 17:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[инвестиции, инвесторы, юридические вопросы, р...</td>\n",
       "      <td>Венчурный процесс глазами юриста: проверка ста...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/investment-law</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2015-12-04 17:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Одноклассники, офис, офисы, российские и зару...</td>\n",
       "      <td>Штаб-квартира: Петербургский и рижский офисы с...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/ok-offices</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-04 17:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Как обезопасить себя при прослушивании телефон...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/problem-14485</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>2015-12-04 17:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Коллекция GIF: почему никто не собирается копи...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/gif-steal-ideas</td>\n",
       "      <td>8277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>2015-12-04 16:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Facebook, вирусы]</td>\n",
       "      <td>По российскому сегменту Facebook распространяе...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/fb-virus-2015</td>\n",
       "      <td>33857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>2015-12-04 16:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[мосгорсуд, блокировка Rutracker]</td>\n",
       "      <td>Мосгорсуд вынес второе решение о пожизненной б...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/rutracker-mosgorsud</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>2015-12-04 15:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[стартапы, ларчик]</td>\n",
       "      <td>«Ларчик» — сервис по доставке материалов для р...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/p/larchik</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments              date source  \\\n",
       "0         4  2015-12-04 21:23    NaN   \n",
       "1       139  2015-12-04 22:20    NaN   \n",
       "2         2  2015-12-04 18:18    NaN   \n",
       "3        15  2015-12-04 17:52    NaN   \n",
       "4        24  2015-12-04 17:40    NaN   \n",
       "5         2  2015-12-04 17:17    NaN   \n",
       "6        15  2015-12-04 17:16    NaN   \n",
       "7        10  2015-12-04 16:45    NaN   \n",
       "8        20  2015-12-04 16:42    NaN   \n",
       "9        25  2015-12-04 15:21    NaN   \n",
       "\n",
       "                                                tags  \\\n",
       "0                                             [uber]   \n",
       "1  [научные исследования, британские учёные, глуп...   \n",
       "2                                                 []   \n",
       "3  [инвестиции, инвесторы, юридические вопросы, р...   \n",
       "4  [Одноклассники, офис, офисы, российские и зару...   \n",
       "5                                                 []   \n",
       "6                                                 []   \n",
       "7                                 [Facebook, вирусы]   \n",
       "8                  [мосгорсуд, блокировка Rutracker]   \n",
       "9                                 [стартапы, ларчик]   \n",
       "\n",
       "                                               title  type  \\\n",
       "0  Украинское министерство инфраструктуры анонсир...    VC   \n",
       "1  Глупость любителей «глубокомысленных» цитат по...  TJ_P   \n",
       "2  Samsung выплатит Apple $548 млн за нарушение п...    VC   \n",
       "3  Венчурный процесс глазами юриста: проверка ста...    VC   \n",
       "4  Штаб-квартира: Петербургский и рижский офисы с...    VC   \n",
       "5  Как обезопасить себя при прослушивании телефон...    VC   \n",
       "6  Коллекция GIF: почему никто не собирается копи...    VC   \n",
       "7  По российскому сегменту Facebook распространяе...    VC   \n",
       "8  Мосгорсуд вынес второе решение о пожизненной б...    VC   \n",
       "9  «Ларчик» — сервис по доставке материалов для р...    VC   \n",
       "\n",
       "                                   url  views  \n",
       "0         https://vc.ru/n/uber-ukraine   2546  \n",
       "1  https://tjournal.ru/p/stupid-quotes  18778  \n",
       "2  https://vc.ru/n/no-one-simply-court   1862  \n",
       "3       https://vc.ru/p/investment-law   2002  \n",
       "4           https://vc.ru/p/ok-offices   2762  \n",
       "5        https://vc.ru/p/problem-14485   1307  \n",
       "6      https://vc.ru/p/gif-steal-ideas   8277  \n",
       "7        https://vc.ru/n/fb-virus-2015  33857  \n",
       "8  https://vc.ru/n/rutracker-mosgorsud   1787  \n",
       "9              https://vc.ru/p/larchik   1466  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!!   !!!!!!!!!! !!!!!!!!!!1 !!!!!!!!!!!!\n",
    "# Сначала почищу данные. Там, где не материалы редакции - мусор, на который твитов то почти и нет!\n",
    "news_info = news_info[ (news_info['type'] == \"VC\") | (news_info[\"type\"] == \"TJ_P\")]\n",
    "len(news_info[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Мерджим дата фреймы\n",
    "df = news_info.merge(tweeter_data, on='url', left_index=True, right_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweeted_count</th>\n",
       "      <th>tw_id</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-12-04 21:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[uber]</td>\n",
       "      <td>Украинское министерство инфраструктуры анонсир...</td>\n",
       "      <td>VC</td>\n",
       "      <td>https://vc.ru/n/uber-ukraine</td>\n",
       "      <td>2546</td>\n",
       "      <td>2015-12-05 10:40:05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>673044155057180672</td>\n",
       "      <td>260</td>\n",
       "      <td>1295</td>\n",
       "      <td>149</td>\n",
       "      <td>16</td>\n",
       "      <td>13002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments              date source    tags  \\\n",
       "0         4  2015-12-04 21:23    NaN  [uber]   \n",
       "\n",
       "                                               title type  \\\n",
       "0  Украинское министерство инфраструктуры анонсир...   VC   \n",
       "\n",
       "                            url  views           created_at  favorite_count  \\\n",
       "0  https://vc.ru/n/uber-ukraine   2546  2015-12-05 10:40:05               0   \n",
       "\n",
       "   is_retweet  retweeted_count               tw_id  user_favourites_count  \\\n",
       "0           0                0  673044155057180672                    260   \n",
       "\n",
       "   user_followers_count  user_friends_count  user_listed_count  \\\n",
       "0                  1295                 149                 16   \n",
       "\n",
       "   user_statuses_count  \n",
       "0                13002  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_date_minutes(news_date, tweet_date):\n",
    "    news_date = datetime.strptime(news_date, '%Y-%m-%d %H:%M')\n",
    "    tweet_date = datetime.strptime(tweet_date, '%Y-%m-%d %H:%M:%S')\n",
    "    return int((tweet_date-news_date).total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# количество минут, с момента публикации записи, данного твита\n",
    "df[\"time_since_news\"] = df.apply(lambda s: diff_date_minutes(s[\"date\"], s[\"created_at\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_week_day(date):\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "    return date.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# индекс дня недели\n",
    "df[\"week_day_news\"] = df.date.apply(lambda s: get_week_day(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minutes_since_midnight(date):\n",
    "    midnight = date.split(\" \")[0] + \" 00:00\"\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "    midnight = datetime.strptime(midnight, '%Y-%m-%d %H:%M')\n",
    "    return int((date-midnight).total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сколько минут времени прошло с полуночи\n",
    "df[\"minutes_since_midnight\"] = df.date.apply(lambda s: get_minutes_since_midnight(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Агрегируем данные из твиттера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Время для вычисления независимых переменных\n",
    "FIRST_TIME = 10\n",
    "# Время для вычисления целевой функции\n",
    "LAST_TIME = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft_df = df[df[\"time_since_news\"] <= FIRST_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = ft_df.groupby(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем общее количество твиттов\n",
    "count_of_tweets = pd.DataFrame(grouped[\"url\"].count())\n",
    "count_of_tweets.columns = [\"first_time_tweet\"]\n",
    "count_of_tweets.reset_index(inplace=True)  \n",
    "df = pd.merge(df, count_of_tweets, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Считаем общую аудиторию\n",
    "follower_sum = pd.DataFrame(grouped[\"user_followers_count\"].sum())\n",
    "follower_sum.columns = [\"follower_sum\"]\n",
    "follower_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, follower_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем число ретвитов\n",
    "retweeted_count_sum = pd.DataFrame(grouped[\"retweeted_count\"].sum())\n",
    "retweeted_count_sum.columns = [\"retweeted_count_sum\"]\n",
    "retweeted_count_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, retweeted_count_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем число звездочек\n",
    "favorite_count_sum = pd.DataFrame(grouped[\"favorite_count\"].sum())\n",
    "favorite_count_sum.columns = [\"favorite_count_sum\"]\n",
    "favorite_count_sum.reset_index(inplace=True)  \n",
    "df = pd.merge(df, favorite_count_sum, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считаем общее число списков, в которых состоят сделавшие посты\n",
    "user_listed_count = pd.DataFrame(grouped[\"user_listed_count\"].sum())\n",
    "user_listed_count.columns = [\"user_listed_count_sum\"]\n",
    "user_listed_count.reset_index(inplace=True)  \n",
    "df = pd.merge(df, user_listed_count, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_df = df[df[\"time_since_news\"] <= LAST_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Выделяем значение целевой функции\n",
    "grouped = st_df.groupby(\"url\")\n",
    "count_of_tweets = pd.DataFrame(grouped[\"url\"].count())\n",
    "count_of_tweets.columns = [\"last_time_tweet\"]\n",
    "count_of_tweets.reset_index(inplace=True)  \n",
    "df = pd.merge(df, count_of_tweets, on='url', left_index=True, right_index=False, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREPARED_CSV = \"prepared_to_analys.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняемся\n",
    "df.to_csv(PREPARED_CSV, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"url\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# После первого запуска, через несколько дней, запускать только часть, которая находится под этим заголовком!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOURS = 8 # Количество часов от текущего момента. Текущее время - Hours часов - время последней собранной новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качаем новости с  2015-11-21 16:19  и  2015-12-04 18:18  по  2015-12-05 09:49\n",
      "https://tjournal.ru/p/christmas-trees-around-the-world\n",
      "https://tjournal.ru/p/lesya-echo-off\n",
      "https://tjournal.ru/p/stupid-quotes\n",
      "https://tjournal.ru/p/ads-evolution\n",
      "https://tjournal.ru/p/chemezov-putin-uchebnik-computer\n",
      "https://tjournal.ru/p/ingress-trucker\n",
      "https://tjournal.ru/p/truckers-riot-moscow-4-december\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-302-b6764b0173e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Качаем новости с VC и TJ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_new_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_prev_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHOURS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;31m# Качаем новости RSS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mrss_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_news_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-302-b6764b0173e3>\u001b[0m in \u001b[0;36mload_new_news\u001b[1;34m(news_df, hours)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtj_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTJLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mtj_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtj_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tj_news_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtj_last_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mvc_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVCLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-299-a1620c46e440>\u001b[0m in \u001b[0;36mget_tj_news_info\u001b[1;34m(self, min_index, count, first_date, last_date)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mis_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[0mlink_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_link_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[1;31m# Если заданное время не подходит\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlink_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mfirst_date\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlink_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlast_date\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-299-a1620c46e440>\u001b[0m in \u001b[0;36mget_link_info\u001b[1;34m(self, link)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mс\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mд\u001b[0m\u001b[0;31mа\u001b[0m\u001b[0;31mн\u001b[0m\u001b[0;31mн\u001b[0m\u001b[0;31mы\u001b[0m\u001b[0;31mм\u001b[0m\u001b[0;31mи\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mс\u001b[0m\u001b[0;31mо\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mс\u001b[0m\u001b[0;31mт\u001b[0m\u001b[0;31mр\u001b[0m\u001b[0;31mа\u001b[0m\u001b[0;31mн\u001b[0m\u001b[0;31mи\u001b[0m\u001b[0;31mц\u001b[0m\u001b[0;31mы\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \"\"\"\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 449\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m             return self.do_open(httplib.HTTPSConnection, req,\n\u001b[1;32m-> 1240\u001b[1;33m                 context=self._context)\n\u001b[0m\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# XXX what error?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1051\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_content_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmessage_body\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[1;31m#message_body was not a string (i.e. it is a file) and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[1;34m\"Connect to a host on a given (SSL) port.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m             \u001b[0mHTTPConnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m         self.sock = self._create_connection((self.host,self.port),\n\u001b[1;32m--> 832\u001b[1;33m                                            self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/popka/anaconda/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mmeth\u001b[1;34m(name, self, *args)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socketmethods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_hours_ago(hours=3):\n",
    "    d = datetime.now() - timedelta(hours=hours)\n",
    "    d = str(d).split(\":\")\n",
    "    d = d[0]+\":\"+d[1]\n",
    "    return d\n",
    "\n",
    "\n",
    "def load_new_news(news_df, hours=3):\n",
    "    # Вычисляем самую молодую новость\n",
    "    tj_last_date = (news_df[news_df[\"type\"]==\"TJ_P\"][\"date\"]).max()\n",
    "    #tj_c_last_date = (news_df[news_df[\"type\"]==\"TJ_C\"][\"date\"]).max()\n",
    "    \n",
    "    #tj_last_date = max(tj_p_last_date, tj_c_last_date)\n",
    "    vc_last_date = (news_df[news_df[\"type\"]==\"VC\"][\"date\"]).max()\n",
    "    first_date = get_hours_ago(hours)\n",
    "    \n",
    "    \n",
    "    print \"Качаем новости с \", tj_last_date,\" и \", vc_last_date, \" по \", first_date\n",
    "    \n",
    "    tj_loader = TJLoader()\n",
    "    tj_pages = tj_loader.get_tj_news_info(min_index=0, count=4, first_date=first_date, last_date=tj_last_date)    \n",
    "    \n",
    "    vc_loader = VCLoader()\n",
    "    vc_pages = vc_loader.get_tj_news_info(first_date=first_date, last_date=vc_last_date)\n",
    "    \n",
    "    pages = vc_pages + tj_pages\n",
    "    pages\n",
    "    \n",
    "    return pages\n",
    "\n",
    "# Загружаем данные\n",
    "news_prev_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "twitter_prev_df = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")\n",
    "\n",
    "# Качаем новости с VC и TJ\n",
    "pages = load_new_news(news_prev_df, HOURS)\n",
    "# Качаем новости RSS\n",
    "rss_pages = s.get_news_array()\n",
    "# Объединяем\n",
    "pages += rss_pages\n",
    "\n",
    "tw = TwitterLoader()\n",
    "tweets = tw.load_tweets_by_term(pages)\n",
    "\n",
    "# Объединяем новости с предыдущими\n",
    "news = pd.DataFrame(pages)\n",
    "news = (news.append(news_prev_df)).reset_index(drop=True)\n",
    "\n",
    "# Объединяем твиты с предыдущими\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df = (tweets_df.append(twitter_prev_df)).reset_index(drop=True)\n",
    "\n",
    "# Сохраняем\n",
    "tweets_df.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "news.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# УДАЛЯЕМ ПОВТОРЫ =((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено  3734\n"
     ]
    }
   ],
   "source": [
    "# Сначала для твиттера\n",
    "tw_data = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")\n",
    "last_size = len(tw_data)\n",
    "dupl = tw_data[\"tw_id\"].duplicated()\n",
    "dupl = np.invert((dupl.as_matrix()))\n",
    "tw_data = tw_data[dupl]\n",
    "print \"Удалено \", last_size-len(tw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем!\n",
    "tw_data.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено  143\n"
     ]
    }
   ],
   "source": [
    "# Теперь для новостей\n",
    "news_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "last_size = len(news_df)\n",
    "dupl = news_df[\"url\"].duplicated()\n",
    "dupl = np.invert((dupl.as_matrix()))\n",
    "news_df = news_df[dupl]\n",
    "print \"Удалено \", last_size-len(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем\n",
    "news_df.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Здесь уже нет ничего хорошего. Уходи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news = news.append(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# читаем данные\n",
    "news_df = pd.read_csv(OUT_NEWS_FILE, sep=\",\")\n",
    "twitter_df = pd.read_csv(OUT_TWITTER_FILE, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# находим самую \"молодую новость\"\n",
    "news_df = news_df.sort_values(by=[\"date\"], ascending=False)\n",
    "tj_last_date = (news_df[news_df[\"type\"]==\"TJ_P\"][\"date\"]).max()\n",
    "vc_last_date = (news_df[news_df[\"type\"]==\"VC\"][\"date\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-11-25 12:56'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-11-25 12:56'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tj_news_info(self, min_index=1, count=30, first_date=\"2015-11-25 12:58\", last_date=\"2015-11-29 12:58\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TJLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0fdcd4c482a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# скачивае информацию о новостях\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTJLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tj_news_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"2015-11-25 12:58\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"2015-11-29 12:58\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TJLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# скачивае информацию о новостях\n",
    "loader = TJLoader()\n",
    "pages = loader.get_tj_news_info(min_index=0, count=30, first_date=\"2015-11-25 12:58\", last_date=\"2015-11-29 12:58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "news_df = news_df.append(pd.DataFrame(pages))\n",
    "news_df.to_csv(OUT_NEWS_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Скачиваем данные из твиттера\n",
    "tw = TwitterLoader()\n",
    "tweeter_data = tw.load_tweets_by_term(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tweeter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в файлик\n",
    "twitter_df = twitter_df.append(pd.DataFrame(tweeter_data))\n",
    "twitter_df.to_csv(OUT_TWITTER_FILE, sep=\",\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = datetime.now() - timedelta(hours=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = str(d).split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = requests.get(\"https://api.vc.ru/1/paper\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_req = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xd0\\x9f\\xd0\\x9e\\xd0\\xa6\\xd0\\x95\\xd0\\x9b\\xd0\\xa3\\xd0\\x99'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element html at 0x7f8cf07d6628>\n"
     ]
    }
   ],
   "source": [
    "page = html.parse(urlopen(\"https://vc.ru/p/interview-it\"))\n",
    "root = page.getroot()\n",
    "print root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft открыла собственный онлайн-магазин в России\n",
      "5865\n",
      "19\n",
      "['microsoft', u'\\u0438\\u043d\\u0442\\u0435\\u0440\\u043d\\u0435\\u0442-\\u043c\\u0430\\u0433\\u0430\\u0437\\u0438\\u043d']\n"
     ]
    }
   ],
   "source": [
    "page = html.parse(urlopen(\"https://vc.ru/n/microsoft-store-russia\"))\n",
    "root = page.getroot()\n",
    "\n",
    "# заголовок\n",
    "title = root.find_class(\"b-article__head\")\n",
    "title = title[0].find(\"h1\").text\n",
    "print title\n",
    "\n",
    "# парсим количество просмотров\n",
    "view = root.get_element_by_id(\"hitsCount\").text\n",
    "view = view.replace(\" \", \"\")\n",
    "view = int(view)\n",
    "print view\n",
    "\n",
    "# Количество комментариев\n",
    "comments = root.find_class(\"ccount\")[0].text\n",
    "comment = int(comments.replace(\" \", \"\"))\n",
    "print comment\n",
    "\n",
    "tags = root.find_class(\"b-tags__tag\")\n",
    "tag_list = []\n",
    "for tag in tags:\n",
    "    tag_list.append(tag.text)\n",
    "    \n",
    "print tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какие вы любите сэндвичи\n"
     ]
    }
   ],
   "source": [
    "print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VCLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comments': 19,\n",
       " 'date': u'2015-11-24 22:13',\n",
       " 'tags': ['microsoft',\n",
       "  u'\\u0438\\u043d\\u0442\\u0435\\u0440\\u043d\\u0435\\u0442-\\u043c\\u0430\\u0433\\u0430\\u0437\\u0438\\u043d'],\n",
       " 'title': u'Microsoft \\u043e\\u0442\\u043a\\u0440\\u044b\\u043b\\u0430 \\u0441\\u043e\\u0431\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u044b\\u0439 \\u043e\\u043d\\u043b\\u0430\\u0439\\u043d-\\u043c\\u0430\\u0433\\u0430\\u0437\\u0438\\u043d \\u0432 \\u0420\\u043e\\u0441\\u0441\\u0438\\u0438',\n",
       " 'views': 5915}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.get_link_info(\"https://vc.ru/n/microsoft-store-russia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачали  10  страниц\n",
      "Скачали  20  страниц\n",
      "Скачали  30  страниц\n",
      "Скачали  40  страниц\n",
      "Скачали  50  страниц\n"
     ]
    }
   ],
   "source": [
    "vc_dict = vc.get_tj_news_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопросы:\n",
    "\n",
    "1) Что делать с соурсе? Эти новости никто не репостит с TJournal, а от других источников их можно найти\n",
    "\n",
    "2) Урлы для других запросов на VC. Не хотелось бы их брудфорсить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
